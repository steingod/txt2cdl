#!/usr/bin/perl -w
#
# NAME:
# txt2cdl
#
# PURPOSE:
# To convert various ASCII files to CDL format for subsequent conversion
# to netCDF using ncgen. See function usage for details on supported file
# formats.
#
# REQUIREMENTS:
# o Getopt::Std;
# o Time::Local;
# o Date::Parse; 
# o Date::Manip;
# o POSIX qw(strftime);
# o Text::Wrap;
#
# INPUT:
# See function usage 
#
# OUTPUT:
# See function usage 
#
# NOTES:
# Handling of conversion between various timezones is implemented for some
# of the file formats supported, some have also support for conversion
# between character formats (UTF-8 -> ISO 8859-1), but this is still not
# implemented in a fully generic fashion. Probably, the full system should
# be rewritten in time...
#
# Handling of CTD data as a single file should be rewritten to dump the
# data in separate files. Separate files improves useability for users
# searching a specific area, especially when the shopping basket is
# implemented.
#
# BUGS:
# Input checking is yet not properly imeplemented, but baseline
# functionality for the formats supported are implemented.
#
# AUTHOR:
# Øystein Godøy, METNO/FOU, 09.05.2007 
#
# MODIFIED:
# Øystein Godøy, METNO/FOU, 11.05.2007
# Øystein Godøy, METNO/FOU, 11.03.2008: Added support for WOCE CTD-format.
# Øystein Godøyy, METNO/FOU, 17.10.2008: Added support for AWI Helicopter
# Ice Thickness measurements.
# Øystein Godøy, METNO/FOU, 19.10.2008: Adding ITP conversion
# Øystein Godøy, METNO/FOU, 24.10.2008: Adding conversion of radiation
# flux data from Bear Island.
# Øystein Godøy, METNO/FOU, 25.10.2008: Bug fix ITP-handling.
# Øystein Godøy, METNO/FOU, 30.10.2008: Bug fix on AWIEM-handling.
# Øystein Godøy, METNO/FOU, 26.11.2008: Added ASCII-format for moorings.
# Øystein Godøy, METNO/FOU, 27.12.2008: Added quality control of DLI
# measurements at Bear Island. Manual inspection and time windows are
# being used as well as inverting the signal between April and
# December 
# Øystein Godøy, METNO/FOU, 14.02.2009: Added support for Vagabond CTD
# data and started rewrite of CTD handling of SeaBird profiles. These need
# special care as they measure both downwards and upwards. Implementation
# is yet not finished.
# Øystein Godøy, METNO/FOU, 06.10.2009: Biological data from NDF/Tromsø¸ is
# now supported through ASCII dump of Excel.
# Øystein Godøy, METNO/FOU, 06.10.2009: Added Oxygen support for ITPs.
# Øystein Godøy, METNO/FOU, 03.11.2009: Added Hopen to radiative flux
# measurements.
# Øystein Godøy, METNO/FOU, 24.03.2010: Modified quality control of Hopen.
# Øystein Godøy, METNO/FOU, 02.06.2010: Modified support for NFH BIO
# sediment data.
# Øystein Godøy, METNO/FOU, 03.06.2010: Modified support for NFH BIO
# stations.
# Øystein Godøy, METNO/FOU, 07.06.2010: Addition of UGOT CTD data
# translation. Assumes UTF-8 encoding of these files.
# Øystein Godøy, METNO/FOU, 17.09.2010: Changed iAOOS biological data
# conversion due to typo discovered concerning degrees_west versus
# degrees_east.
# Øystein Godøy, METNO/FOU, 2011-01-17: Added biomass support.
# Øystein Godøy, METNO/FOU, 09.05.2012: Added support for new gliders.
# Øystein Godøy, METNO/FOU, 2012-11-06: Added support for 7 new gliders.
# Øystein Godøy, METNO/FOU, 2013-06-20: Modification for radiative fluxes.
# Øystein Godøy, METNO/FOU, 2013-08-28: Added support for change in
# character encoding.
# Øystein Godøy, METNO/FOU, 2013-08-29: Added quality statements for
# radiative fluxes in 2013.
#
# CVS_ID:
# $Id: txt2cdl,v 1.64 2013-08-29 14:05:49 steingod Exp $
#  

########################################################### 
# Requirements
use strict;
use Getopt::Std;
use Time::Local;
use Text::Wrap;
use Date::Parse;
use Date::Manip;
use POSIX qw(strftime);
use Encode;
use Encode::Detect::Detector;
use encoding "utf-8";
use vars qw($opt_i $opt_o $opt_a $opt_m $opt_t $opt_e $opt_k $opt_v $opt_r $opt_c $opt_g $opt_b $opt_p $opt_h $opt_u $opt_f $opt_n $opt_q $opt_v $opt_z $opt_y);

########################################################### 
# Prototypes
sub usage;
sub year_and_day2epoch;
sub read_file;
sub create_ctd_cdl_woce;
sub create_ctd_cdl_seabirdnfh;
sub create_itp_cdl;
sub create_mooring_cdl_mooringgfi;
sub create_mooring_cdl_ascii;
sub create_trajectory_cdl_awiem;
sub create_timeseries_cdl_radflux;
sub create_cdl_nfhbiosed;
sub create_cdl_nfhbiomass;
sub create_cdl_nfhbio;
sub create_cdl_ugotctd;
sub write_file;
sub sort_matrix;

my($ifn,$ofn,@text,$fileformat,$cdlhead);
my($template_file, @template, $line, @cdloutput);
my($piname,$title,$topic,$keyw,$gcmdkeyw,$email,$area,$inst,$vessel);
my($distribution,$abstract,$history,$url,$pname,$qual);
my($project_name,$activity_type);

########################################################### 
# Option decoding
usage if !getopts('i:o:a:m:t:e:k:r:g:v:c:g:p:b:h:u:f:n:q:v:z:y:');
usage if ((! $opt_i) || (!$opt_o) || (!$opt_f) || (!$opt_m));
$ifn = $opt_i;
$ofn = $opt_o;
if ($opt_f) {
    $fileformat = $opt_f;
} else {
    $fileformat = "";
}
if ($opt_g) {
    $inst = $opt_g;
} else {
    $inst = "";
}
if ($opt_a) {
    $piname = $opt_a;
} else {
    $piname = "";
}
if ($opt_t) {
    $title = $opt_t;
} else {
    $title = "";
}
if ($opt_p) {
    $topic = $opt_p;
} else {
    $topic = "";
}
if ($opt_y) {
    $activity_type = $opt_y;
} else {
    $activity_type = "";
}
if ($opt_z) {
    $project_name = $opt_z;
} else {
    $project_name = "";
}
if ($opt_k) {
    $keyw = $opt_k;
} else {
    $keyw = "";
}
if ($opt_v) {
    $gcmdkeyw = $opt_v;
} else {
    $gcmdkeyw = "";
}
if ($opt_e) {
    $email = $opt_e;
} else {
    $email = "";
}
if ($opt_r) {
    $area = $opt_r;
} else {
    $area = "";
}
if ($opt_b) {
    $abstract = $opt_b;
} else {
    $abstract = "";
}
if ($opt_n) {
    $pname = $opt_n;
} else {
    $pname = "";
}
if ($opt_v) {
    $vessel = $opt_v;
} else {
    $vessel = "";
}
if ($opt_c) {
    $distribution = $opt_c;
} else {
    $distribution = "Free";
}
if ($opt_u) {
    $url = $opt_u;
} else {
    $url = "";
}
if ($opt_h) {
    $history = $opt_h;
} else {
    $history = strftime("%F",gmtime(time))." creation";
}
if ($opt_m) {
    $template_file = $opt_m;
} else {
    $template_file = "";
}
if ($opt_q) {
    $qual = $opt_q;
} else {
    $qual = "Unknown quality";
}

###########################################################
# Read template file
print "\n";
print " Reading file: $template_file\n";
@template = read_file($template_file);

########################################################### 
# Read input data
print "\n";
print " Reading file: $ifn\n";
@text = read_file($ifn);

###########################################################
# Extract information from input file and create CDL structure
print "\n";
print " Converting data to CDL\n";
if ($fileformat eq "seabirdctd") {
    @cdloutput = create_ctd_cdl_seabird(\@template,\@text);
} elsif ($fileformat eq "wocectd") {
    @cdloutput = create_ctd_cdl_woce(\@template,\@text);
} elsif ($fileformat eq "itp") {
    @cdloutput = create_itp_cdl(\@template,\@text);
} elsif ($fileformat eq "mooring") {
    @cdloutput = create_mooring_cdl_ascii(\@template,\@text);
} elsif ($fileformat eq "mooringgfi") {
    @cdloutput = create_mooring_cdl_mooringgfi(\@template,\@text);
} elsif ($fileformat eq "awiem") {
    @cdloutput = create_trajectory_cdl_awiem(\@template,\@text);
} elsif ($fileformat eq "metnoradflux") {
    @cdloutput = create_timeseries_cdl_radflux(\@template,\@text);
} elsif ($fileformat eq "nfhbiosed") {
    @cdloutput = create_cdl_nfhbiosed(\@template,\@text);
} elsif ($fileformat eq "nfhbiomass") {
    @cdloutput = create_cdl_nfhbiomass(\@template,\@text);
} elsif ($fileformat eq "nfhbio") {
    @cdloutput = create_cdl_nfhbio(\@template,\@text);
} elsif ($fileformat eq "ugotctd") {
    @cdloutput = create_cdl_ugotctd(\@template,\@text);
} else {
    die "Fileformat ($fileformat) is not supported\n";
}

########################################################### 
# Add header information
unless ($fileformat eq "awiem" or $fileformat eq "metnoradflux" or
    $fileformat eq "mooring") {
    s/\+title/$title/ for (@cdloutput);
    s/\+abstract/$abstract/ for (@cdloutput);
    s/\+topic/$topic/ for (@cdloutput);
    s/\+keyw/$keyw/ for (@cdloutput);
    s/\+gcmdkeyw/$gcmdkeyw/ for (@cdloutput);
    s/\+activity_type/$activity_type/ for (@cdloutput);
    s/\+project_name/$project_name/ for (@cdloutput);
    s/\+area/$area/ for (@cdloutput);
    s/\+inst/$inst/ for (@cdloutput);
    s/\+piname/$piname/ for (@cdloutput);
    s/\+email/$email/ for (@cdloutput);
    s/\+distribution/$distribution/ for (@cdloutput);
    s/\+vessel/$vessel/ for (@cdloutput);
    s/\+pname/$pname/ for (@cdloutput);
    s/\+history/$history/ for (@cdloutput);
    s/\+url/$url/ for (@cdloutput);
    s/\+qual/$qual/ for (@cdloutput);
}

########################################################### 
# Create output file
$cdlhead = $ofn;
$cdlhead =~ s/(\.cdl)|(\.txt)|(\.dat)//;
$cdloutput[0] =~ s/template_\w+ /$cdlhead /;
print "\n";
print " Writing file: $ofn\n";
die " Could not write output file\n" if (! write_file($ofn, @cdloutput));
print "\n";

exit;

########################################################### 
#
#
########################################################### 
# Function definitions
########################################################### 
#
#
########################################################### 

#
# Usage description
#
sub usage() {
    $Text::Wrap::columns = 74;

    my $text = "This software transforms various ASCII formats into CDL files which can be converted to netCDF by ncgen. The file formats supported may change.";
    my $formats = 
    "o WOCE CTD ASCII format - (format=wocectd) NA yet\n".
    "o SeaBird ASCII format (several versions) - (format=seabirdctd)\n".
    "o Current mooring format by GFI, Bergen, Norway - (format=mooringgfi)\n".
    "o Current mooring format in ASCII - (format=mooring)\n".
    "o Helicopter trajectory of ice thickness by AWI, Germany - (format=awiem)\n".
    "o ITP-data from Woods Hole, daily updates - (format=itp)\n".
    "o METNO radiative flux measurements, continous stream -
    (format=metnoradflux)\n".
    "o BIO sediment data from UiT, Norway - (format=nfhbiosed)\n".
    "o BIOmass data from UiT, Norway - (format=nfhbiomass)\n".
    "o BIO data from UiT, Norway - (format=nfhbio)\n".
    "o CTD data from UGOT, Sweden - (format=ugotctd)";
    my $author = "Øystein Godøy, METNO/FOU, 03.06.2010";

    print "\n";
    print wrap("","\t","$0 -i <infile> -o <outfile> -f <format> -m
        <template>\n [-a <author> -e <email> -g <institution> -u <url>\n -t
        <title> -b <abstract> -v <platform> -n <product_name>\n -p <topic> -k
        <keywords> -v <gcmdkeywords>\n -r <area_covered> -c <distribution> -h
        <history>\n -q <quality> -y <activity> -z <project> -v <gcmdkw>]\n");
    print "\n";
    print "\t<infile>: Some supported ASCII file,\n".
    "\t\tif a directory it tries to process contents\n";
    print "\t<outfile>: CDL file according to CF standard,\n".
    "\t\tif infile is a directory this should be a directory\n";
    print "\t<format>: Input file format, se below\n";
    print "\t<template>: CDL template file according to CF standard\n";
    print "\t<author>: PI name\n";
    print "\t<email>: PI or responsible person email address\n";
    print "\t<institution>: Name of institution\n";
    print "\t<url>: URL of institution/PI\n";
    print "\t<title>: Title of dataset\n";
    print "\t<abstract>: Short description of data\n";
    print "\t<platform>: E.g. name of the research vessel used\n";
    print "\t<product_name>: Product name\n";
    print "\t<topic>: Topic category of dataset (predefined list)\n";
    print "\t<keywords>: Keywords of dataset (predefined list)\n";
    print "\t<area_covered>: Area of observation (predefined list)\n";
    print "\t<distribution>: Data distribution statement (free, restricted)\n";
    print "\t<history>: Short description of data history\n";
    print "\t<quality>: \"Unknown quality\", \"Excellent\",\"Fair\",\"Questionable\"\n";
    print "\n";
    print wrap("\t", "\t", $text);
    print "\n\n";
    print wrap("\t", "\t", $formats);
    print "\n\n";
    print "\t$author\n";
    print "\n";
    exit;
}

#
# Convert year and decimal days to epoch time
#
sub year_and_day2epoch($$) {
    my($myyear,$myday) = @_;
    my($timeepoch,$timestr);

    $timestr = sprintf "%4d-01-01 00:00 GMT", $myyear;

    #print "$myyear $myday ";

    $timeepoch = str2time($timestr);
    $myday -= 1;
    $myday *= (24*3600.);

    $timeepoch += int($myday);

    #print "$myday $timeepoch\n";

    return($timeepoch);
}

#
# Read a file
#
sub read_file($) {

    my($filename) = @_;
    my(@text, $enc);

    open FH, "<$filename" or die " Could not open file $filename\n";
    @text = <FH>;
    close FH;

    $enc = Encode::Detect::Detector::detect(join('',@text));
    print "File has encoding: $enc\n";

    open FH, "<encoding($enc)","$filename" or die " Could not open file $filename\n";
    @text = <FH>;
    close FH;

    return(@text);
}

#
# Dump CDL code
#
sub write_file($@) {

    my($filename,@text) = @_;
    my($line);

    open FH, ">:encoding(UTF-8)","$filename" or die " Could not open file $filename\n";
    foreach $line (@text) {
        print FH "$line";
    }
    close FH;

    return(1);
}

#
# Decode and convert WOCE ASCII CTD files
#
sub create_ctd_cdl_woce {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my($tmpstr, $yy, $mm, $dd, $hh, $ii);
    my(@timearr,$timeunix, $timestr);
    my(@mytmp,$pname,$vessel,$lat,$lon,$nvalues);
    my($pres,$temp,$psal);
    my($pres_flg,$temp_flg,$psal_flg);
    my($line,$norec);

    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # First the necessary information is extracted from the input data

    # Sensor name
    $pname = $txtref->[0];
    $pname =~ s/[\n\r]//;

    # Time
    @mytmp = grep /^DATE = /,@$txtref;
    chop($mytmp[0]);
    $mytmp[0] =~ s/DATE = //g;
    $yy = substr $mytmp[0],0,4;
    $mm = substr $mytmp[0],4,2;
    $dd = substr $mytmp[0],6,2;
    @mytmp = grep /^TIME = /,@$txtref;
    chop($mytmp[0]);
    $mytmp[0] =~ s/TIME = //g;
    $hh = substr $mytmp[0],0,2;
    $ii = substr $mytmp[0],2,2;
    $timestr = sprintf("%4d-%02d-%02d %02d:%02d:%02d UTC", 
        $yy, $mm, $dd, $hh, $ii, 0);
    $timeunix = str2time($timestr);

    # Latitude
    @mytmp = grep /^LATITUDE = /,@$txtref;
    $lat = substr((split /=/,$mytmp[0])[1],0,-1);

    # Longitude
    @mytmp = grep /^LONGITUDE = /,@$txtref;
    $lon = substr((split /=/,$mytmp[0])[1],0,-1);

    # Data records
    @mytmp = grep /^\ |^[0-9]/,@$txtref;
    s/^(\s+)// for (@mytmp);
    s/\s+/ /g for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    $norec = 0;
    foreach $line (@mytmp) {
        @tmparr = split /,/,$line;
        $pres .= "$tmparr[0],";
        $pres_flg .= "$tmparr[1],";
        $temp .= "$tmparr[2],";
        $temp_flg .= "$tmparr[3],";
        $psal .= "$tmparr[4],";
        $psal_flg .= "$tmparr[5],";
        $norec++;
    }
    print "$norec pressure levels found in file, abort if incorrect...\n";
    $nvalues = $norec;
    $pres =~s/,$//;
    $temp =~s/,$//;
    $psal =~s/,$//;

    ########################################################### 
    # Then this information is substituted into the CDL template

    s/\+nvalues/$nvalues/ for (@cdlout);
    s/\+pname/$pname/ for (@cdlout); # Actually a global variabel
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+time/$timeunix/ for (@cdlout);
    s/\+YYYY\-MM\-DD HH\:MM\:SS UTC/$timestr/ for (@cdlout);
    s/\+pres/$pres/ for (@cdlout);
    s/\+temp/$temp/ for (@cdlout);
    s/\+psal/$psal/ for (@cdlout);

    return(@cdlout);
}

#
# Decode and convert a specific SEABIRD format used by NFH/TromsÃÂ¸
#
sub create_ctd_cdl_seabird {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@timearr,$timeunix,$timeunixcast,$timestr);
    my(@mytmp,@mytmp2,$tmpstr,$pname,$vessel,$lat,$lon,$nvalues,$ncol,$i,$j);
    my($pres,$temp,$cond,$psal,$depth);
    my($line,$norec);

    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # First the necessary information is extracted from the input data
    # stream

    # Sensor name
    $pname = $txtref->[0];
    $pname =~ s/(^(\* ))|://g;
    $pname =~ s/[\n\r]//g;

    if (grep /Vagabond/,@$txtref) {
        # Time
        @mytmp = grep /^\# start_time = /,@$txtref;
        @timearr = split /=/,$mytmp[0];
        $timestr = $timearr[1];
        $timestr =~ s/^\s+//;
        $timestr =~ s/\n$//;
        ##$timestr = substr $mytmp[0],11,21;
        $timeunix = str2time($timestr."UTC");
        die "\n\tThe time specification of this dataset is obviously incorrect...\n\n" if ($timeunix > time || $timeunix < 86400);
        $timeunixcast = $timeunix;
        undef(@timearr);
        @timearr = gmtime($timeunix);
        $timestr = strftime("%F %T UTC",@timearr);

        if (grep /Vagabond/,@$txtref) {
            @mytmp = grep /^\*\* Vagabond/,@$txtref;
            $tmpstr = $mytmp[0];
            @mytmp =  split /-/,$tmpstr;
            $vessel = "Vagabond";
            if ($mytmp[1] =~ m/\d+/) {
                $lat = (substr $mytmp[1],1,2)+((substr $mytmp[1],4,2)+(substr $mytmp[1],7,2)/100.)/60.;
                $lon = (substr $mytmp[2],1,2)+((substr $mytmp[2],4,2)+(substr $mytmp[2],7,2)/100.)/60.;
            } elsif ($mytmp[2] =~ m/\d+/) {
                $lat = (substr $mytmp[2],1,2)+((substr $mytmp[2],4,2)+(substr $mytmp[2],7,2)/100.)/60.;
                $lon = (substr $mytmp[3],1,2)+((substr $mytmp[3],4,2)+(substr $mytmp[3],7,2)/100.)/60.;
            } else {
                $lat = (substr $mytmp[3],1,2)+((substr $mytmp[3],4,2)+(substr $mytmp[3],7,2)/100.)/60.;
                $lon = (substr $mytmp[4],1,2)+((substr $mytmp[4],4,2)+(substr $mytmp[4],7,2)/100.)/60.;
            }
        } else {
            die "Cannot interprete this format...\n";
        }

    } elsif ($pname =~ "Sea-Bird SBE 9 Data File") {
# Time
        @mytmp = grep /^\* NMEA UTC \(Time\) = /,@$txtref;
        $timestr = (split /=/,$mytmp[0])[1];
        $timestr =~ s/[\n\r]//g;
        $timestr =~ s/\s+/ /g;
        $timeunix = str2time($timestr);
        @timearr = gmtime($timeunix);
        $timestr = strftime("%F %T UTC",@timearr);

# Vessel
        @mytmp = grep /^\*\* Ship: /,@$txtref;
        $vessel = (split /:/,$mytmp[0])[1];
        $vessel =~ s/^(\s+)//;
        $vessel =~ s/[\n\r]//g;

# Latitude
        @mytmp = grep /^\* NMEA Latitude = /,@$txtref;
        $lat = (split /=/,$mytmp[0])[1];
        $lat =~ s/^ //;
        @mytmp = split / /,$lat,3;
        $lat = $mytmp[0]+($mytmp[1]/60.);
        $mytmp[2] =~ s/[\n\r]//g;
        $lat *= (-1.) if ($mytmp[2] eq "S");

# Longitude
        @mytmp = grep /^\* NMEA Longitude = /,@$txtref;
        $lon = (split /=/,$mytmp[0])[1];
        $lon =~ s/^ //;
        @mytmp = split / /,$lon,3;
        $lon = $mytmp[0]+($mytmp[1]/60.);
        $mytmp[2] =~ s/[\n\r]//g;
        $lon *= (-1.) if ($mytmp[2] eq "W");
    }

    # Number of columns
    @mytmp = grep /^\# nquan = /,@$txtref;
    $ncol = (split /=/,$mytmp[0])[1];
    $ncol =~ s/[\s\n\r]//g;

    # Number of records
    @mytmp = grep /^\# nvalues = /,@$txtref;
    $nvalues = (split /=/,$mytmp[0])[1];
    $nvalues =~ s/[\s\n\r]//g;

    # Data records
    @mytmp = grep /^\s/,@$txtref;
    s/^(\s+)// for (@mytmp);
    s/\s+/ /g for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    undef @mytmp2;
    $i = 0;
    foreach $line (@mytmp) {
        my @columns = split /\s+/,$line;
        $mytmp2[$i++] = \@columns;
}
@mytmp = sort { $a->[2] <=> $b->[2] } @mytmp2;
#map { print join(" ", @$_),"\n";} @mytmp;
#$norec = 0;
if ($vessel =~ /Vagabond/) {
    undef($timeunix);
    for ($i=0;$i<=$#mytmp;$i++) {
        $timeunix .= "$mytmp[$i][1],";
        $depth .= "$mytmp[$i][2],";
        $temp .= "$mytmp[$i][3],";
        $cond .= "$mytmp[$i][5],";
        $psal .= "$mytmp[$i][4],";
    }
} else {
    for ($i=0;$i<=$#mytmp;$i++) {
        $pres .= "$mytmp[$i][1],";
        $temp .= "$mytmp[$i][2],";
        $cond .= "$mytmp[$i][3],";
        $psal .= "$mytmp[$i][4],";
        #$norec++;
    }
}
#warn "Data records: nvalues ($nvalues) and norec ($norec) differ\n" if ($nvalues != $norec);
if ($vessel =~ /Vagabond/) {
    $timeunix =~s/,$//;
    $depth =~s/,$//;
    $temp =~s/,$//;
    $cond =~s/,$//;
    $psal =~s/,$//;
} else {
    $pres =~s/,$//;
    $temp =~s/,$//;
    $cond =~s/,$//;
    $psal =~s/,$//;
}

########################################################### 
# Then this information is substituted into the CDL template

s/\+nvalues/$nvalues/ for (@cdlout);
s/\+pname/$pname/ for (@cdlout); # Actually a global variabel
s/\+vessel/$vessel/ for (@cdlout); # Actually a global variabel
s/\+lat/$lat/ for (@cdlout);
s/\+lon/$lon/ for (@cdlout);
s/\+time/$timeunixcast/ for (@cdlout);
if ($vessel =~ /Vagabond/) {
    s/\+sampletime/$timeunix/ for (@cdlout);
    s/time:units = "seconds since 1970-01-01 00:00:00 UTC"/time:units = "seconds since $timestr"/ for (@cdlout);
}
s/\+start_date/$timestr/ for (@cdlout);
s/\+stop_date/$timestr/ for (@cdlout);
if ($vessel =~ /Vagabond/) {
    s/\+depth/$depth/ for (@cdlout);
} else {
    s/\+pres/$pres/ for (@cdlout);
}
s/\+temp/$temp/ for (@cdlout);
s/\+cond/$cond/ for (@cdlout);
s/\+psal/$psal/ for (@cdlout);

return(@cdlout);
}

#
# Decode and convert the mooring format of GFI/UiB
#
sub create_mooring_cdl_mooringgfi {

    my(@cdlout,@tmparr,$tmpstr);
    my($tempref,$txtref) = @_;
    my(@timearr,$timeunix,$timestr,$timeline);
    my(@mytmp,$pname,$vessel,$lat,$lon,$nvalues);
    my($speed,$directiontemp,$ucomp,$vcomp,$temp,$psal,$pres);
    my($line,$norec,$depth,$instrid,$u,$v,$nlevels,$direction);
    my($start_date,$stop_date,$nparam,$params);
    my($sflg,$dflg,$uflg,$vflg,$tflg,$pflg,$aflg);

    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # First the necessary information is extracted from the input data
    # stream

    # Header begins with %
    @mytmp = grep /^\%/,@$txtref;

    s/\%// for (@mytmp);
    @tmparr = split /=/,$mytmp[0];

    # Instrument identification
    $instrid = $tmparr[0]; 
    $instrid =~ s/ N.*$//;

    # Parameters in the file, code is as following
    # F - speed, A - direction, U - u component, V - v component,
    # T - temperature, P - pressure, S - salinity
    $params = $tmparr[1];
    $params =~s/^(\s+[0-9]+\s)//g;
    $tmpstr = (split / +/,$params)[0];
    $params = $tmpstr;
    $sflg = ($params =~ /F/)?1:0;
    $dflg = ($params =~ /A/)?1:0;
    $uflg = ($params =~ /U/)?1:0;
    $vflg = ($params =~ /V/)?1:0;
    $tflg = ($params =~ /T/)?1:0;
    $pflg = ($params =~ /P/)?1:0;
    $aflg = ($params =~ /S/)?1:0;

    # Number of datarecords
    $nvalues = $tmparr[1]; 
    $nvalues =~ s/\s|[a-zA-Z]//g;

    # Number of levels
    $nlevels = 1;

    # Date of deployment
    $timestr = sprintf("%4d-%02d-%02d %02d:%02d:%02d UTC",
        (2000+substr($tmparr[3],0,2)),
        substr($tmparr[3],2,2),
        substr($tmparr[3],4,2),
        substr($tmparr[3],7,2),
        substr($tmparr[3],9,2),
        0);
    $start_date = $timestr;

    # Depth
    $depth = $tmparr[4]; 
    $depth =~ s/\s|[a-zA-Z]//g;

    # Latitude
    $tmpstr = $tmparr[5];
    $lat = substr($tmpstr,1,2)+
    (substr($tmpstr,3,2)+(substr($tmpstr,5,2)/100.))/60.;
    $lat *= -1. if ($tmpstr =~ /S/);

    # Longitude
    $lon= substr($tmpstr,8,3)+
    (substr($tmpstr,11,2)+(substr($tmpstr,13,2)/100.))/60.;
    $lon *= -1. if ($tmpstr =~ /W/);

    # Data records
    @mytmp = grep !/(^\%)/,@$txtref;
    s/^(\s+)// for (@mytmp);
    s/\s+/ /g for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    $norec = 0;
    foreach $line (@mytmp) {
        @tmparr = split / /,$line;
        $timearr[0] = 0;
        $timearr[1] = $tmparr[4];
        $timearr[2] = $tmparr[3];
        $timearr[3] = $tmparr[2];
        $timearr[4] = $tmparr[1]-1;
        $timearr[5] = $tmparr[0]+100;
        $timestr = strftime("%F %T UTC",@timearr);
        $timeunix = timegm(@timearr);
        $timeline .= "$timeunix,";
        $speed .= "$tmparr[5]," if ($sflg);
        $direction .= "$tmparr[6]," if ($dflg);
        $u .= "$tmparr[7]," if ($uflg);
        $v .= "$tmparr[8]," if ($vflg);
        $temp .= "$tmparr[9]," if ($tflg);
        $psal .= "$tmparr[10]," if ($aflg);
        $pres .= "$tmparr[11]," if ($pflg);
        $norec++;
    }
    $stop_date = $timestr;
    $timeline =~s/,$//;
    $speed =~s/,$// if ($sflg);
    $direction =~s/,$// if ($dflg);
    $u =~s/,$// if ($uflg);
    $v =~s/,$// if ($vflg);
    $pres =~s/,$// if ($pflg);
    $temp =~s/,$// if ($tflg);
    $psal =~s/,$// if ($aflg);

    ########################################################### 
    # Then this information is substituted into the CDL template

    # First remove variables not supported
    if ($sflg == 0) {
        @tmparr = grep(!/speed/,@cdlout);
        @cdlout = @tmparr;
    }
    unless ($dflg) {
        @tmparr = grep !/direction/,@cdlout;
        @cdlout = @tmparr;
    }
    unless ($uflg) {
        @tmparr = grep !/ucomp/,@cdlout;
        @cdlout = @tmparr;
    }
    unless ($vflg) {
        @tmparr = grep !/vcomp/,@cdlout;
        @cdlout = @tmparr;
    }
    unless ($tflg) {
        @tmparr = grep !/temp/,@cdlout;
        @cdlout = @tmparr;
    }
    unless ($pflg) {
        @tmparr = grep !/pres/,@cdlout;
        @cdlout = @tmparr;
    }
    unless ($aflg) {
        @tmparr = grep !/psal/,@cdlout;
        @cdlout = @tmparr;
    }

    s/\+nlevels/$nlevels/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+start_date/$start_date/ for (@cdlout);
    s/\+stop_date/$stop_date/ for (@cdlout);
    s/\+depth/$depth/ for (@cdlout);
    s/\+time/$timeline/ for (@cdlout);
    if ($pflg) {
        s/\+pres/$pres/ for (@cdlout);
    }
    if ($sflg) {
        s/\+speed/$speed/ for (@cdlout);
    }
    if ($dflg) { 
        s/\+direction/$direction/ for (@cdlout);
    }
    if ($uflg) { 
        s/\+ucomp/$u/ for (@cdlout);
    }
    if ($vflg) { 
        s/\+vcomp/$v/ for (@cdlout);
    }
    if ($tflg) {
        s/\+temp/$temp/ for (@cdlout);
    }
    if ($aflg) { 
        s/\+psal/$psal/ for (@cdlout);
    }

    return(@cdlout);
}

#
# Decode and convert the ITP level2 format used by Woods Hole Institute
# for Ice Tethered Platforms.
#
sub create_itp_cdl {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@timearr,$timeunix,$timestr_start,$timestr_end,$timeunixref);
    my(@mytmp,$pname,$hours,$hourref,$timeofdata,$lat,$lon,$nvalues);
    my($nlat,$slat,$wlon,$elon);
    my($myvariables,$myunits,$thickness,$altitude,$myurl);
    my($myhistory,$start_date,$stop_date,$institution,$contact,$myarea);
    my($conventions,$distribution_statement,$project_name,$productname);
    my($topiccategory,$mykeywords,$mygcmdkeywords,$activity_type,$PI_name);
    my($line,$norec,$misvalin,$misvalout);
    my($itpid,$profileid,$vessel,$quality);
    my($myyear,$myday,$pressure,$temperature,$salinity,$oxygen);
    my $variables1 = "%year day pressure(dbar) temperature(C) salinity";
    my $variables2 = "%pressure(dbar) temperature(C) salinity nobs";
    my $variables3 = "%year day pressure(dbar) temperature(C) salinity oxygen(umol/kg)";
    my($ftype,%projectnames,@witho2);

    ###########################################################
    # Do some initialization
    $misvalin = "Nan";
    $misvalout = -999.;
    $title = "";
    $abstract = "The Ice-Tethered Profiler data were collected and made available by the Ice-Tethered Profiler Program based at the Woods Hole Oceanographic Institution (http://www.whoi.edu/itp). ITP data are similar to CTD data, but are collected from buoys frozen in the sea ice.";
    $productname = "ITP profile";
    $myarea = "Arctic Ocean";
    $topiccategory = "oceans";
    $mykeywords = "pressure temperature salinity";
    $mygcmdkeywords = "Oceans > Ocean Temperature > Water Temperature\nOceans > Salinity/Density > Salinity\nOceans > Ocean Pressure > Water Pressure";
    $activity_type = "Float";
    $vessel = "";
    $myhistory = "";
    $distribution_statement = "Free";
    $conventions = "CF-1.0";
    $PI_name = "Not available";
    $institution = "Woods Hole Oceanographic Institute";
    $contact = "itp\@whoi.edu";
    $myurl = "http://www.whoi.edu/itp/";
    $project_name = "Damocles";
    $start_date = "";
    $stop_date = "";
    $quality = "Level 2 data";
    %projectnames = (
        "1" => "Beaufort Gyre Observing System (BGOS)",
        "2" => "Beaufort Gyre Freshwater Experiment (BGFE)",
        "3" => "Beaufort Gyre Observing System (BGOS)",
        "4" => "Beaufort Gyre Observing System (BGOS)",
        "5" => "Beaufort Gyre Observing System (BGOS)",
        "6" => "Beaufort Gyre Observing System (BGOS)",
        "7" => "North Pole Environmental Observatory (NPEO)",
        "8" => "Beaufort Gyre Observing System (BGOS)",
        "9" => "Damocles",
        "10" => "Damocles",
        "11" => "Damocles",
        "12" => "Damocles",
        "13" => "Beaufort Gyre Observing System (BGOS)",
        "14" => "Damocles",
        "15" => "Damocles",
        "16" => "Damocles",
        "17" => "Damocles",
        "18" => "Beaufort Gyre Observing System (BGOS)",
        "19" => "North Pole Environmental Observatory (NPEO)",
        "20" => "Beaufort Gyre Observing System (BGOS)",
        "21" => "Beaufort Gyre Observing System (BGOS)",
        "22" => "Beaufort Gyre Observing System (BGOS)",
        "23" => "Beaufort Gyre Observing System (BGOS)",
        "24" => "Damocles",
        "25" => "Damocles",
        "26" => "Damocles",
        "27" => "Damocles",
        "28" => "Damocles",
        "29" => "Damocles",
        "30" => "Beaufort Gyre Observing System (BGOS)",
        "31" => "Not available",
        "32" => "Beaufort Gyre Observing System (BGOS)",
        "33" => "Beaufort Gyre Observing System (BGOS)",
        "34" => "Beaufort Gyre Observing System (BGOS)",
        "36" => "Nansen and Amundsen Basins Observational System (NABOS)",
        "37" => "Nansen and Amundsen Basins Observational System (NABOS)",
        "38" => "North Pole Environmental Observatory (NPEO)",
        "40" => "National Institute of Water and Atmospheric Research (NIWA)",
        "41" => "Beaufort Gyre Observing System (BGOS)",
        "42" => "Beaufort Gyre Observing System (BGOS)",
        "43" => "Beaufort Gyre Observing System (BGOS)",
        "44" => "Beaufort Gyre Observing System (BGOS)",
        "47" => "North Pole Environmental Observatory (NPEO)",
        "48" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "49" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "50" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "51" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "52" => "Beaufort Gyre Observing System (BGOS)",
        "53" => "Beaufort Gyre Observing System (BGOS)",
        "54" => "Beaufort Gyre Observing System (BGOS)",
        "55" => "Beaufort Gyre Observing System (BGOS)",
        "56" => "North Pole Environmental Observatory (NPEO)",
        "57" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "58" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "60" => "Hybrid Arctic/Antarctic Float Observation System (HAFOS)",
        "62" => "Beaufort Gyre Observing System (BGOS)",
        "63" => "NP-39 drifting ice station (no project specified)",
        "64" => "Beaufort Gyre Observing System (BGOS)",
        "65" => "Beaufort Gyre Observing System (BGOS)",
        "66" => "Beaufort Gyre Observing System (BGOS)",
    );
    #@witho2 = (6,13,23,29);

    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    # File records
    @mytmp = @$txtref;
    s/\ +/ /g for (@mytmp);
    s/^\ |\ $// for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    if ($variables1 eq $mytmp[2]) {
        $ftype = "level 2";
    } elsif ($variables2 eq $mytmp[2]) {
        $ftype = "level 3";
    } elsif ($variables3 eq $mytmp[2]) {
        $ftype = "level 4";
    } else {
        die "Could not recognise file type.";
    }
    $norec = 0;
    foreach $line (@mytmp) {
        if ($norec == 0){
            $line =~ s/^\%//;
            @tmparr = (split /,/,$line);
            $itpid = $tmparr[0];
            $itpid =~ s/\D*//;
            $profileid = (split /:/,$tmparr[1])[0];
            $profileid =~ s/\D*//;
            $norec++;
            next;
        }
        if ($norec == 1) {
            $line =~ s/^\ +/ /g;
            @tmparr = (split / /,$line);
            $myyear = $tmparr[0];
            $myday = $tmparr[1];
            $timeunix = year_and_day2epoch($myyear,$myday);
            @timearr = gmtime($timeunix);
            $timestr_start = strftime("%F %T UTC",@timearr);
            $timestr_end = $timestr_start;
            $lon = $tmparr[2];
            $lat = $tmparr[3];
            $nvalues = $tmparr[4];
            @tmparr = gmtime(time);
            if ($myyear > ($tmparr[5]+1901)) {
                die "Year of observation is out of scope!";
            }
            if ($lat > 90. || $lat < -90. || $lon > 360. || $lon < -360) {
                die "Geographical position out of scope!";
            }
            $norec++;
            next;
        }
        if ($line =~ m/^\%/){
            $norec++;
            next;
        }
        @tmparr = split / /,$line;
        if ($ftype eq "level 2") {
            $myyear = $tmparr[0];
            $myday = $tmparr[1];
            $timeunix = year_and_day2epoch($myyear,$myday);
        }
        $timeofdata .= $timeunix.",";
        if ($norec == 3) {
            @timearr = gmtime($timeunix);
            $timestr_end = strftime("%F %T UTC",@timearr);
        }
        if ($ftype eq "level 3") {
            $pressure .= $tmparr[0].",";
            $temperature .= $tmparr[1].",";
            $salinity .= $tmparr[2].",";
        } elsif ($ftype eq "level 4") {
            $pressure .= $tmparr[2].",";
            $temperature .= $tmparr[3].",";
            $salinity .= $tmparr[4].",";
            $oxygen .= $tmparr[5].",";
        } else {
            $pressure .= $tmparr[2].",";
            $temperature .= $tmparr[3].",";
            $salinity .= $tmparr[4].",";
        }
        $norec++;
    }
    warn "Data records: nvalues ($nvalues) and norec ($norec-4) differ\n" if ($nvalues != $norec-4);
    $timeofdata =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $pressure =~ s/,$//;
    $salinity =~ s/,$//;
    $temperature =~ s/,$//;
    $oxygen =~ s/,$// if ($ftype eq "level 4");

    $title .= sprintf "ITP %02d Profile",$itpid;
    $vessel = sprintf "ITP %02d",$itpid;
    $project_name = "$projectnames{$itpid}";
    $myhistory = sprintf "%s creation",strftime("%F",gmtime(time));

    ########################################################### 
    # Then this information is substituted into the CDL template

    s/\+title/$title/ for (@cdlout);
    s/\+abstract/$abstract/ for (@cdlout);
    s/\+topic/$topiccategory/ for (@cdlout);
    s/\+keyw/$mykeywords/ for (@cdlout);
    s/\+gcmdkeyw/$mygcmdkeywords/ for (@cdlout);
    s/\+area/$myarea/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+url/$myurl/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+pname/$productname/ for (@cdlout);
    s/\+project_name/$project_name/ for (@cdlout);
    s/\+activity_type/$activity_type/ for (@cdlout);
    s/\+history/$myhistory/ for (@cdlout);
    s/\+vessel/$vessel/ for (@cdlout);
    s/\+nlat/$lat/ for (@cdlout);
    s/\+slat/$lat/ for (@cdlout);
    s/\+wlon/$lon/ for (@cdlout);
    s/\+elon/$lon/ for (@cdlout);
    s/\+start_date/$timestr_start/ for (@cdlout);
    s/\+stop_date/$timestr_end/ for (@cdlout);
    s/\+nvalues/$nvalues/ for (@cdlout);
    s/\+time/$timeofdata/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+temp/$temperature/ for (@cdlout);
    s/\+psal/$salinity/ for (@cdlout);
    s/\+pres/$pressure/ for (@cdlout);
    if ($ftype eq "level 4") {
        s/\+oxygen/$oxygen/ for (@cdlout); 
    }
    s/\+qual/$quality/ for (@cdlout);
    splice @cdlout,10,1,"variables:\n\t:profile_number = $profileid;\n";

    return(@cdlout);
}

#
# Decode and convert the column based ASCII format that can be used to
# store morring data. 
#
sub create_mooring_cdl_ascii {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@timearr,$timeunix,$timestr_start,$timestr_end,$timeunixref);
    my($timeunixref2007,$year,$month,$day,$hour);
    my(@mytmp,$pname,$timeofdata,$lat,$lon,$nvalues,$depth);
    my($myvariables,$myunits,$speed,$direction);
    my($pressure,$salinity,$temperature,$myurl,$platformname);
    my($myhistory,$start_date,$stop_date,$institution,$contact,$myarea);
    my($conventions,$distribution_statement,$project_name,$productname);
    my($topiccategory,$mykeywords,$mygcmdkeywords,$activity_type,$PI_name);
    my($line,$norec,$misvalin,$misvalout,$quality_statement);

    ###########################################################
    # Do some initialization
    $misvalin = "NaN";
    $misvalout = 9999.;
    $title = "";
    $abstract = "";
    $productname = "";
    $platformname = "";
    $myarea = "";
    $topiccategory = "";
    $mykeywords = "";
    $mygcmdkeywords = "";
    $activity_type = "";
    $myhistory = "";
    $distribution_statement = "";
    $conventions = "";
    $PI_name = "";
    $institution = "";
    $contact = "";
    $myurl = "";
    $project_name = "";
    $quality_statement = "";
    $start_date = "";
    $stop_date = "";


    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # First the necessary information is extracted from the input data
    # stream

    # title
    @mytmp = grep /^# title: /,@$txtref;
    unless ($#mytmp == -1) {
        $title = (split /:/,$mytmp[0])[1];
        $title =~ s/[\n\r]//g;
        $title =~ s/^\ //;
    }

    # abstract
    @mytmp = grep /^# abstract: /,@$txtref;
    unless ($#mytmp == -1) {
        $abstract = (split /:/,$mytmp[0])[1];
        $abstract =~ s/[\n\r]//g;
        $abstract =~ s/^\ //;
    }

    # topiccatergory
    @mytmp = grep /^# topiccategory: /,@$txtref;
    unless ($#mytmp == -1) {
        $topiccategory = (split /:/,$mytmp[0])[1];
        $topiccategory =~ s/[\n\r]//g;
        $topiccategory =~ s/,\ */ /g;
        $topiccategory =~ s/^\s//g;
    }

    # keywords
    @mytmp = grep /^# keywords: /,@$txtref;
    unless ($#mytmp == -1) {
        $mykeywords = (split /:/,$mytmp[0])[1];
        $mykeywords =~ s/^\s//g;
        $mykeywords =~ s/[\n\r]//g;
        $mykeywords =~ s/,/ /g;
    }

    # gcmd_keywords
    @mytmp = grep /^# gcmd_keywords: /,@$txtref;
    unless ($#mytmp == -1) {
        $mygcmdkeywords = (split /:/,$mytmp[0])[1];
        $mygcmdkeywords =~ s/^\s//g;
        $mygcmdkeywords =~ s/[\n\r]//g;
        $mygcmdkeywords =~ s/,/ /g;
    }

    # activity_type
    @mytmp = grep /^# activity_type: /,@$txtref;
    unless ($#mytmp == -1) {
        $activity_type = (split /:/,$mytmp[0])[1];
        $activity_type =~ s/[\n\r]//g;
        $activity_type =~ s/^\s//g;
    }

    # Conventions
    @mytmp = grep /^# Conventions: /,@$txtref;
    unless ($#mytmp == -1) {
        $conventions = (split /:/,$mytmp[0])[1];
        $conventions =~ s/[\n\r]//g;
    }

    # product_name
    @mytmp = grep /^# product_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $productname = (split /:/,$mytmp[0])[1];
        $productname =~ s/[\n\r]//g;
        $productname =~ s/^\s//g;
    }

    # platform_name
    @mytmp = grep /^# platform: /,@$txtref;
    unless ($#mytmp == -1) {
        $platformname = (split /:/,$mytmp[0])[1];
        $platformname =~ s/[\n\r]//g;
        $platformname =~ s/^\s//;
    }

    # Measurement level
    @mytmp = grep /^# measurement_level: /,@$txtref;
    unless ($#mytmp == -1) {
        $depth = (split /:/,$mytmp[0])[1];
        $depth =~ s/[\n\r]//g;
        die "Measurement level has to specified in meter" unless $depth =~ m/meter/;
        $depth =~ s/^\s//g;
        $depth =~ s/meter//g;
    }

    # history
    @mytmp = grep /^# history: /,@$txtref;
    unless ($#mytmp == -1) {
        $myhistory = (split /:/,$mytmp[0])[1];
        $myhistory =~ s/^\s//g;
        $myhistory =~ s/[\n\r]//g;
        $myhistory =~ s/,\s*/\n/g;
    }

    # area
    @mytmp = grep /^# area: /,@$txtref;
    unless ($#mytmp == -1) {
        $myarea = (split /:/,$mytmp[0])[1];
        $myarea =~ s/[\n\r]//g;
        $myarea =~ s/^\s//g;
    }

    # northernmost_latitude
    @mytmp = grep /^# northernmost_latitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $lat = (split /:/,$mytmp[0])[1];
        $lat =~ s/^ //;
        $lat =~ s/[\n\r]//g;
    }

    # southernmost_latitude
    @mytmp = grep /^# southernmost_latitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $lat = (split /:/,$mytmp[0])[1];
        $lat =~ s/^ //;
        $lat =~ s/[\n\r]//g;
    }

    # westernmost_longitude
    @mytmp = grep /^# westernmost_longitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $lon = (split /:/,$mytmp[0])[1];
        $lon =~ s/^ //;
        $lon =~ s/[\n\r]//g;
    }

    # easternmost_longitude
    @mytmp = grep /^# easternmost_longitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $lon = (split /:/,$mytmp[0])[1];
        $lon =~ s/^ //;
        $lon =~ s/[\n\r]//g;
    }

    # start_date
    @mytmp = grep /^# start_date: /,@$txtref;
    unless ($#mytmp == -1) {
        $start_date = (split /:/,$mytmp[0])[1];
        $start_date =~ s/[\n\r]//g;
        $timeunix = str2time($start_date,"UTC");
        $timeunixref = $timeunix;
        @timearr = gmtime($timeunix);
        $timestr_start = strftime("%F %T UTC",@timearr);
    }
    $timeunixref2007 = str2time("2007-01-01 00:00:00 UTC");
    $timeunixref -= $timeunixref2007;

    # stop_date
    @mytmp = grep /^# stop_date: /,@$txtref;
    unless ($#mytmp == -1) {
        $stop_date = (split /:/,$mytmp[0])[1];
        $stop_date =~ s/[\r\n]//g;
        $timeunix = str2time($stop_date,"UTC");
        @timearr = gmtime($timeunix);
        $timestr_end = strftime("%F %T UTC",@timearr);
    }

    # institution
    @mytmp = grep /^# institution: /,@$txtref;
    unless ($#mytmp == -1) {
        $institution = (split /:/,$mytmp[0])[1];
        $institution =~ s/[\n\r]//g;
        $institution =~ s/^\s//g;
    }

    # url
    @mytmp = grep /^# url: /,@$txtref;
    unless ($#mytmp == -1) {
        @tmparr = (split /:/,$mytmp[0]);
        $myurl = $tmparr[1].":".$tmparr[2];
        $myurl =~ s/[\n\r]//g;
        $myurl =~ s/^\s//g;
    }

    # PI_name
    @mytmp = grep /^# PI_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $PI_name = (split /:/,$mytmp[0])[1];
        $PI_name =~ s/[\n\r]//g;
        $PI_name =~ s/^\s//g;
    }

    # contact
    @mytmp = grep /^# contact: /,@$txtref;
    unless ($#mytmp == -1) {
        $contact = (split /:/,$mytmp[0])[1];
        $contact =~ s/[\s]//g;
    }

    # distribution_statement
    @mytmp = grep /^# distribution_statement: /,@$txtref;
    unless ($#mytmp == -1) {
        $distribution_statement = (split /:/,$mytmp[0])[1];
        $distribution_statement =~ s/[\n\r]//g;
        $distribution_statement =~ s/[\s]//;
    }

    # project_name
    @mytmp = grep /^# project_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $project_name = (split /:/,$mytmp[0])[1];
        $project_name =~ s/[\s]//g;
    }

    # quality statement
    @mytmp = grep /^# quality_statement: /,@$txtref;
    unless ($#mytmp == -1) {
        $quality_statement = (split /:/,$mytmp[0])[1];
        $quality_statement =~ s/^\s//g;
        $quality_statement =~ s/[\n\r]//g;
    }

    # variables
    @mytmp = grep /^# variables: /,@$txtref;
    unless ($#mytmp == -1) {
        $myvariables = (split /:/,$mytmp[0])[1];
        $myvariables =~ s/[\s]//g;
        die "Incorrect variables for this format specification" unless ($myvariables eq "year,month,day,hour,speed,dir,temp,salt,pres");
    }

    # units
    @mytmp = grep /^# units: /,@$txtref;
    unless ($#mytmp == -1) {
        $myunits = (split /:/,$mytmp[0])[1];
        $myunits =~ s/[\s]//;
        $myunits =~ s/[\r\n]//;
        unless ($myunits eq "NA,NA,NA,NA,cm/s,degrees from north,celsius,PSU,dbar") {
            print "$myunits\n";
            die "Incorrect unit specification for this format" 
        }
    }

    # Nvalues
    @mytmp = grep /^\# number of observations: /,@$txtref;
    unless ($#mytmp == -1) {
        $nvalues = (split /:/,$mytmp[0])[1];
        $nvalues =~ s/[\s\n\r]//g;
    }

    # Data records
    @mytmp = grep /^\d/,@$txtref;
    s/\ +/ /g for (@mytmp);
    s/^\ |\ $// for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    $norec = 0;
    foreach $line (@mytmp) {
        next if (length($line) == 0);
        @tmparr = split / /,$line;
        $year = $tmparr[0];
        $month = $tmparr[1];
        $day = $tmparr[2];
        $hour = $tmparr[3];
        $timeunix = str2time(sprintf("%4d-%02d-%02d %02d:00:00 UTC",$year,$month,$day,$hour),"UTC");
        $timeofdata .= "$timeunix,"; 
        $speed .= "$tmparr[4],";
        $direction .= "$tmparr[5],";
        $temperature .= "$tmparr[6],";
        $salinity .= "$tmparr[7],";
        $pressure .= "$tmparr[8],";
        $norec++;
    }
    warn "Data records: nvalues ($nvalues) and norec ($norec) differ\n" if ($nvalues != $norec);
    $timeofdata =~ s/,$//;
    $speed =~ s/,$//;
    $speed =~ s/$misvalin/$misvalout/g;
    $direction =~ s/,$//;
    $direction =~ s/$misvalin/$misvalout/g;
    $temperature =~ s/,$//;
    $temperature =~ s/$misvalin/$misvalout/g;
    $salinity =~ s/,$//;
    $salinity =~ s/$misvalin/$misvalout/g;
    $pressure =~ s/,$//;
    $pressure =~ s/$misvalin/$misvalout/g;

    ########################################################### 
    # Then this information is substituted into the CDL template

    s/\+title/$title/ for (@cdlout);
    s/\+abstract/$abstract/ for (@cdlout);
    s/\+topic/$topiccategory/ for (@cdlout);
    s/\+keyw/$mykeywords/ for (@cdlout);
    s/\+gcmdkeyw/$mygcmdkeywords/ for (@cdlout);
    s/\+area/$myarea/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+url/$myurl/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+pname/$productname/ for (@cdlout);
    s/\+projectname/$project_name/ for (@cdlout);
    s/\+vessel/$platformname/ for (@cdlout);
    s/\+quality/$quality_statement/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+history/$myhistory/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+start_date/$timestr_start/ for (@cdlout);
    s/\+stop_date/$timestr_end/ for (@cdlout);
    s/\+nlevels/1/ for (@cdlout);
    s/\+depth/$depth/ for (@cdlout);
    s/\+time/$timeofdata/ for (@cdlout);
    s/\+speed/$speed/ for (@cdlout);
    s/\+direction/$direction/ for (@cdlout);
    s/\+pres/$pressure/ for (@cdlout);
    s/\+temp/$temperature/ for (@cdlout);
    s/\+psal/$salinity/ for (@cdlout);

    return(@cdlout);
}


#
# Decode and convert a specific trajectory format used by AWI for ice
# thickness measurements from helicopter.
#
sub create_trajectory_cdl_awiem {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@timearr,$timeunix,$timestr_start,$timestr_end,$timeunixref);
    my($timeunixref2007);
    my(@mytmp,$pname,$hours,$hourref,$timeofdata,$lat,$lon,$nvalues);
    my($nlat,$slat,$wlon,$elon);
    my($myvariables,$myunits,$thickness,$altitude,$myurl);
    my($myhistory,$start_date,$stop_date,$institution,$contact,$myarea);
    my($conventions,$distribution_statement,$project_name,$productname);
    my($topiccategory,$mykeywords,$mygcmdkeywords,$activity_type,$PI_name);
    my($line,$norec,$misvalin,$misvalout,$quality_statement);

    ###########################################################
    # Do some initialization
    $misvalin = "Nan";
    $misvalout = -999.;
    $title = "";
    $abstract = "";
    $productname = "";
    $myarea = "";
    $topiccategory = "";
    $mykeywords = "";
    $mygcmdkeywords = "";
    $activity_type = "";
    $myhistory = "";
    $distribution_statement = "";
    $conventions = "";
    $PI_name = "";
    $institution = "";
    $contact = "";
    $myurl = "";
    $project_name = "";
    $quality_statement = "";
    $start_date = "";
    $stop_date = "";


    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # First the necessary information is extracted from the input data
    # stream

    # title
    @mytmp = grep /^# title: /,@$txtref;
    unless ($#mytmp == -1) {
        $title = (split /:/,$mytmp[0])[1];
        $title =~ s/[\n\r]//g;
        $title =~ s/^\ //;
    }

    # abstract
    @mytmp = grep /^# abstract: /,@$txtref;
    unless ($#mytmp == -1) {
        $abstract = (split /:/,$mytmp[0])[1];
        $abstract =~ s/[\n\r]//g;
        $abstract =~ s/^\ //;
    }

    # topiccatergory
    @mytmp = grep /^# topiccategory: /,@$txtref;
    unless ($#mytmp == -1) {
        $topiccategory = (split /:/,$mytmp[0])[1];
        $topiccategory =~ s/[\n\r]//g;
        $topiccategory =~ s/,\ */ /g;
        $topiccategory =~ s/^\s//g;
    }

    # keywords
    @mytmp = grep /^# keywords: /,@$txtref;
    unless ($#mytmp == -1) {
        $mykeywords = (split /:/,$mytmp[0])[1];
        $mykeywords =~ s/^\s//g;
        $mykeywords =~ s/[\n\r]//g;
        $mykeywords =~ s/,/ /g;
    }

    # gcmd_keywords
    @mytmp = grep /^# gcmd_keywords: /,@$txtref;
    unless ($#mytmp == -1) {
        $mygcmdkeywords = (split /:/,$mytmp[0])[1];
        $mygcmdkeywords =~ s/^\s//g;
        $mygcmdkeywords =~ s/[\n\r]//g;
        $mygcmdkeywords =~ s/,/ /g;
    }

    # activity_type
    @mytmp = grep /^# activity_type: /,@$txtref;
    unless ($#mytmp == -1) {
        $activity_type = (split /:/,$mytmp[0])[1];
        $activity_type =~ s/[\n\r]//g;
        $activity_type =~ s/^\s//g;
    }

    # Conventions
    @mytmp = grep /^# Conventions: /,@$txtref;
    unless ($#mytmp == -1) {
        $conventions = (split /:/,$mytmp[0])[1];
        $conventions =~ s/[\n\r]//g;
    }

    # product_name
    @mytmp = grep /^# product_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $productname = (split /:/,$mytmp[0])[1];
        $productname =~ s/[\n\r]//g;
        $productname =~ s/^\s//g;
    }

    # history
    @mytmp = grep /^# history: /,@$txtref;
    unless ($#mytmp == -1) {
        $myhistory = (split /:/,$mytmp[0])[1];
        $myhistory =~ s/^\s//g;
        $myhistory =~ s/[\n\r]//g;
        $myhistory =~ s/,\s*/\n/g;
    }

    # area
    @mytmp = grep /^# area: /,@$txtref;
    unless ($#mytmp == -1) {
        $myarea = (split /:/,$mytmp[0])[1];
        $myarea =~ s/[\n\r]//g;
        $myarea =~ s/^\s//g;
    }

    # northernmost_latitude
    @mytmp = grep /^# northernmost_latitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $nlat = (split /:/,$mytmp[0])[1];
        $nlat =~ s/^ //;
        $nlat =~ s/[\n\r]//g;
    }

    # southernmost_latitude
    @mytmp = grep /^# southernmost_latitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $slat = (split /:/,$mytmp[0])[1];
        $slat =~ s/^ //;
        $slat =~ s/[\n\r]//g;
    }

    # westernmost_longitude
    @mytmp = grep /^# westernmost_longitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $wlon = (split /:/,$mytmp[0])[1];
        $wlon =~ s/^ //;
        $wlon =~ s/[\n\r]//g;
    }

    # easternmost_longitude
    @mytmp = grep /^# easternmost_longitude: /,@$txtref;
    unless ($#mytmp == -1) {
        $elon = (split /:/,$mytmp[0])[1];
        $elon =~ s/^ //;
        $elon =~ s/[\n\r]//g;
    }

    # start_date
    @mytmp = grep /^# start_date: /,@$txtref;
    unless ($#mytmp == -1) {
        $start_date = (split /:/,$mytmp[0])[1];
        $start_date =~ s/[\n\r]//g;
        $timeunix = str2time($start_date,"UTC");
        $timeunixref = $timeunix;
        @timearr = gmtime($timeunix);
        $timestr_start = strftime("%F %T UTC",@timearr);
    }
    $timeunixref2007 = str2time("2007-01-01 00:00:00 UTC");
    $timeunixref -= $timeunixref2007;

    # stop_date
    @mytmp = grep /^# stop_date: /,@$txtref;
    unless ($#mytmp == -1) {
        $stop_date = (split /:/,$mytmp[0])[1];
        $stop_date =~ s/[\r\n]//g;
        $timeunix = str2time($stop_date,"UTC");
        @timearr = gmtime($timeunix);
        $timestr_end = strftime("%F %T UTC",@timearr);
    }

    # institution
    @mytmp = grep /^# institution: /,@$txtref;
    unless ($#mytmp == -1) {
        $institution = (split /:/,$mytmp[0])[1];
        $institution =~ s/[\n\r]//g;
        $institution =~ s/^\s//g;
    }

    # url
    @mytmp = grep /^# url: /,@$txtref;
    unless ($#mytmp == -1) {
        @tmparr = (split /:/,$mytmp[0]);
        $myurl = $tmparr[1].":".$tmparr[2];
        $myurl =~ s/[\n\r]//g;
        $myurl =~ s/^\s//g;
    }

    # PI_name
    @mytmp = grep /^# PI_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $PI_name = (split /:/,$mytmp[0])[1];
        $PI_name =~ s/[\n\r]//g;
        $PI_name =~ s/^\s//g;
    }

    # contact
    @mytmp = grep /^# contact: /,@$txtref;
    unless ($#mytmp == -1) {
        $contact = (split /:/,$mytmp[0])[1];
        $contact =~ s/[\s]//g;
    }

    # distribution_statement
    @mytmp = grep /^# distribution_statement: /,@$txtref;
    unless ($#mytmp == -1) {
        $distribution_statement = (split /:/,$mytmp[0])[1];
        $distribution_statement =~ s/[\s]//g;
    }

    # project_name
    @mytmp = grep /^# project_name: /,@$txtref;
    unless ($#mytmp == -1) {
        $project_name = (split /:/,$mytmp[0])[1];
        $project_name =~ s/[\s]//g;
    }

    # quality statement
    @mytmp = grep /^# quality_statement: /,@$txtref;
    unless ($#mytmp == -1) {
        $quality_statement = (split /:/,$mytmp[0])[1];
        $quality_statement =~ s/^\s//g;
        $quality_statement =~ s/[\n\r]//g;
    }

    # variables
    @mytmp = grep /^# variables: /,@$txtref;
    unless ($#mytmp == -1) {
        $myvariables = (split /:/,$mytmp[0])[1];
        $myvariables =~ s/[\s]//g;
        die "Incorrect variables for this format specification" unless ($myvariables eq "latitude,longitude,time,thickness,altitude");
    }

    # units
    @mytmp = grep /^# units: /,@$txtref;
    unless ($#mytmp == -1) {
        $myunits = (split /:/,$mytmp[0])[1];
        $myunits =~ s/[\s]//g;
        die "Incorrect unit specification for this format" unless ($myunits eq "degrees_North,degrees_East,hours,meter,meter");
    }

    # Nvalues
    @mytmp = grep /^\# number of observations: /,@$txtref;
    unless ($#mytmp == -1) {
        $nvalues = (split /:/,$mytmp[0])[1];
        $nvalues =~ s/[\s\n\r]//g;
    }

    # Data records
    @mytmp = grep /^\s/,@$txtref;
    s/\ +/ /g for (@mytmp);
    s/^\ |\ $// for (@mytmp);
    s/[\n\r]//g for (@mytmp);
    $norec = 0;
    foreach $line (@mytmp) {
        next if (length($line) == 0);
        @tmparr = split / /,$line;
        $lat .= "$tmparr[0],";
        $lon .= "$tmparr[1],";
        $hours = $tmparr[2];
        $hourref = int($hours) if ($norec == 0);
        #$timeunix = int(($hours-$hourref)*3600);
        $timeunix = int(($hours-$hourref)*3600*1000);
        ##print "$hours $hourref $timeunix ";
        $timeunix += ($timeunixref*1000);
        ##print "$timeunix $timeunixref\n";
        $timeofdata .= "$timeunix,"; 
        $thickness .= "$tmparr[3],";
        $altitude .= "$tmparr[4],";
        $norec++;
    }
    warn "Data records: nvalues ($nvalues) and norec ($norec) differ\n" if ($nvalues != $norec);
    $timeofdata =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $hours =~ s/,$//;
    $thickness =~ s/,$//;
    $thickness =~ s/$misvalin/$misvalout/g;
    $altitude =~ s/,$//;
    $altitude =~ s/$misvalin/$misvalout/g;

    ########################################################### 
    # Then this information is substituted into the CDL template

    s/\+title/$title/ for (@cdlout);
    s/\+abstract/$abstract/ for (@cdlout);
    s/\+topic/$topiccategory/ for (@cdlout);
    s/\+keyw/$mykeywords/ for (@cdlout);
    s/\+gcmdkeyw/$mygcmdkeywords/ for (@cdlout);
    s/\+area/$myarea/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+url/$myurl/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+distribution_statement/$distribution_statement/ for (@cdlout);
    s/\+pname/$productname/ for (@cdlout);
    s/\+projectname/$project_name/ for (@cdlout);
    s/\+quality/$quality_statement/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+history/$myhistory/ for (@cdlout);
    s/\+nlat/$nlat/ for (@cdlout);
    s/\+slat/$slat/ for (@cdlout);
    s/\+wlon/$wlon/ for (@cdlout);
    s/\+elon/$elon/ for (@cdlout);
    s/\+start_date/$timestr_start/ for (@cdlout);
    s/\+stop_date/$timestr_end/ for (@cdlout);
    s/\+time/$timeofdata/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+thickness/$thickness/ for (@cdlout);
    s/\+altitude/$altitude/ for (@cdlout);

    return(@cdlout);
}

#
# Decode and convert to CDL the METNO radiative flux file format
#
sub create_timeseries_cdl_radflux {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my($norec,$i,$qchit);
    my($stationname,$variables,$datalogger,$procmeth,$activitytype);
    my $varnames = "TIMESTAMP,RECORD,P_Wpm2_Avg,T_gr_C_Avg,P_L_Wpm2_Avg,T_L_gr_C_Avg,Batt_V_Min";
    my $varmeth = ",,Avg,Avg,Avg,Avg,Min";
    my($timestr,$timestr_start,$timestr_end,$obstime,$unixtime);
    my($ssi,$dli,$ssitemp,$dlitemp,$battmin,$nvalues);
    my($misvalin,$misvalout);
    my($topiccategory,$keywords,$gcmdkeywords,$conventions,$history);
    my %stationinfo = 
    (
        "Bjørnøya" => {
            "title" => "Downwelling surface radiative fluxes at Bjørnøya",
            "abstract" => "Downwelling surface radiative fluxes observed at the meteorological station at Bjørnøya in the Barents Sea.  Measurements are made using Kipp and Zonen CMP21 and CGR4 pyranometers and pyrgeometers. Daily maintenance is performed by the meteorological personnel at the station. Data are averaged over the last minute and the time is set to UTC. This data set was originally supported by the Norwegian Research Council but is now continued by the Norwegian Meteorological Institute. The quality control performed is by visual inspection and by comparison of clear sky values against RTM simulations. Originally this station was started as an IPY station funded through iAOOS-Norway and IPY-THORPEX, currently it is continued by METNO.", 
            "product_name" => "radiative fluxes",
            "history" => "2008-10-23 creation",
            "project_name" => "iAOOS-Norway/IPY-THORPEX",
            "area" => "Barents Sea",
            "lat" => 74.5166667,
            "lon" => 19.01666667,
            "institution" => "Norwegian Meteorological Institute",
            "PI_name" => "Øystein Godøy",
            "url" => "http://www.met.no/",
            "contact" => "o.godoy\@met.no",
            "distribution_statement" => "Polar Information Commons (http://polarcommons.org/)/CCBY",
            "quality_statement" => "Quality controlled by visual inspection and RTM comparison",
            "quality_removals" => "6",
            "quality_keys" => {
                "0" => {
                    "par" => "dli",
                    "start" => str2time("2008-01-01 00:00:00","UTC"), 
                    "end" => str2time("2008-04-08 12:22:00","UTC"),
                },
                "1" => {
                    "par" => "dli",
                    "start" => str2time("2008-11-15 11:04:00","UTC"), 
                    "end" => str2time("2008-11-18 10:24:00","UTC"),
                },
                "2" => {
                    "par" => "dli",
                    "start" => str2time("2008-11-21 09:36:00","UTC"), 
                    "end" => str2time("2008-11-21 09:38:00","UTC"),
                },
                "3" => {
                    "par" => "ssi",
                    "start" => str2time("2008-11-21 09:55:00","UTC"), 
                    "end" => str2time("2008-11-21 09:58:00","UTC"),
                },
                "4" => {
                    "par" => "dli",
                    "start" => str2time("2009-01-31 15:04:00","UTC"), 
                    "end" => str2time("2009-02-11 00:00:00","UTC"),
                },
                "5" => {
                    "par" => "dli",
                    "start" => str2time("2011-01-11 09:30:00","UTC"), 
                    "end" => str2time("2011-01-21 12:30:00","UTC"),
                },
            },
        },
        "Jan Mayen" => {
            "title" => "Downwelling surface radiative fluxes at Jan Mayen",
            "abstract" => "Downwelling surface radiative fluxes observed at the meteorological station at Jan Mayen Island in the Greenland Sea. Measurements are made using Kipp and Zonen CMP21 and CGR4 pyranometers and pyrgeometers. Daily maintenance is performed by the meteorological personnel at the station. Data are averaged over the last minute and the time is set to UTC. This data set has been collected with support from the Norwegian Research Council. The quality control performed is by visual inspection and by comparison of clear sky values against RTM simulations. Originally this station was started as an IPY station funded through iAOOS-Norway and IPY-THORPEX, currently it is continued by METNO.",
            "product_name" => "radiative fluxes",
            "history" => "2008-11-23 creation",
            "project_name" => "iAOOS-Norway",
            "area" => "Greenland Sea",
            "lat" => 70.933333,
            "lon" => -8.6666667,
            "institution" => "Norwegian Meteorological Institute",
            "PI_name" => "Øystein Godøy",
            "url" => "http://www.met.no/",
            "contact" => "o.godoy\@met.no",
            "distribution_statement" => "Polar Information Commons (http://polarcommons.org/)/CCBY",
            "quality_statement" => "Quality controlled by visual inspection and RTM comparison",
            "quality_removals" => "2",
            "quality_keys" => {
                "0" => {
                    "par" => "ssi&dli",
                    "start" => str2time("2008-11-01 00:00:00","UTC"), 
                    "end" => str2time("2008-12-03 18:00:00","UTC"),
                },
                "1" => {
                    "par" => "dli",
                    "start" => str2time("2013-02-13 12:57:00","UTC"), 
                    "end" => str2time("2013-07-23 21:23:00","UTC"),
                },
            },
        },
        "Hopen" => {
            "title" => "Downwelling surface radiative fluxes at Hopen",
            "abstract" => "Downwelling surface radiative fluxes observed at the meteorological station at Hopen Island in the Barents Sea. Measurements are made using Kipp and Zonen CMP21 and CGR4 pyranometers and pyrgeometers. Daily maintenance is performed by the meteorological personnel at the station. Data are averaged over the last minute and the time is set to UTC. This data set has been collected with support from the Norwegian Research Council. The quality control performed is by visual inspection and by comparison of clear sky values against RTM simulations. Originally this station was started as an IPY station funded through iAOOS-Norway and IPY-THORPEX, currently it is continued by METNO.",
            "product_name" => "radiative fluxes",
            "history" => "2009-11-03 creation",
            "project_name" => "iAOOS-Norway",
            "area" => "Barents Sea",
            "lat" => 76.5,
            "lon" => 25.07,
            "institution" => "Norwegian Meteorological Institute",
            "PI_name" => "Øystein Godøy",
            "url" => "http://www.met.no/",
            "contact" => "o.godoy\@met.no",
            "distribution_statement" => "Restricted to iAOOS-Norway",
            "quality_statement" => "Quality controlled by visual inspection and RTM comparison",
            "quality_removals" => "2",
            "quality_keys" => {
                "0" => {
                    "par" => "ssi&dli",
                    "start" => str2time("2009-07-21 00:00:00","UTC"), 
                    "end" => str2time("2009-11-01 00:00:00","UTC"),
                },
                "1" => {
                    "par" => "ssi&dli",
                    "start" => str2time("2013-03-24 12:51:00","UTC"), 
                    "end" => str2time("2013-04-09 12:50:00","UTC"),
                },
            },
        },
        "unknown" => {
            "title" => "",
            "abstract" => "",
            "product_name" => "",
            "history" => "",
            "project_name" => "",
            "area" => "",
            "lat" => -999.,
            "lon" => -999.,
            "institution" => "",
            "PI_name" => "",
            "url" => "",
            "contact" => "",
            "distribution_statement" => "",
            "quality_statement" => "",
            "quality_removals" => "0",
            "quality_keys" => "",
        },
    );
    # ########################################################### 
    # Corrections to be made to raw data due to wrong mounting or
    # programming.
    #
    my $invertbidlistart = str2time("2008-04-21 12:15:00","UTC");
    my $invertbidliend = str2time("2008-12-17 07:45:00","UTC");
    my $corrclockjmstart = str2time("2008-11-01 00:00:00","UTC");
    my $corrclockjmend = str2time("2009-02-11 09:27:00","UTC");

    $qchit = 0;
    $misvalin = "NAN";
    $misvalout = -999.;
    $topiccategory = "ClimatologyMeteorologyAtmosphere";
    $keywords = "Radiative Flux";
    $gcmdkeywords = 
    "Atmosphere > Atmospheric Radiation > Shortwave Radiation\n".
    "Atmosphere > Atmospheric Radiation > Longwave Radiation";
    $activitytype = "Land station";

    ###########################################################
    # Copy the template
    @cdlout = @$tempref;

    ########################################################### 
    # Decode header - 4 records
    #
    $norec = 0;
    foreach $line (@$txtref) {
        $line =~ s/["\n\r]//g;
        if ($norec == 0) {
            @tmparr = split /,/,$line;
            $stationname = $tmparr[1];
            $stationname =~ s/ Strålingsstasjon//;
            $stationname =~ s/_Strålingsmåler//;
            $datalogger = $tmparr[2];
        }
        if ($norec==1) {
            $variables = $line; 
            die "Variable names\n\t$variables\ndo not match\n\t$varnames" if ($variables ne $varnames);
        }
        if ($norec==3) {
            $procmeth = $line; 
            die "Variable processing do not match" if ($procmeth ne $varmeth);
        }
        $norec++;
        last if ($norec == 4);
    }
    print "$stationname\n";

    ###########################################################
    # History update
    #
    if (length($stationinfo{$stationname}{history}) > 0) {
        $history = $stationinfo{$stationname}{history}."\n".sprintf "%s revision",strftime("%F",gmtime(time));
    } else {
        $history = sprintf "%s creation",strftime("%F",gmtime(time));
    }

    ########################################################### 
    # Decode data records - 7 variables
    #
    $norec = 0;
    foreach $line (@$txtref) {
        $line =~ s/["\n\r]//g;
        $norec++;
        next if ($norec < 5);
        $line =~ s/["\n\r]//g;
        @tmparr = split /,/,$line;
        $unixtime = str2time($tmparr[0],"UTC");
        # Corrections at Jan Mayen
        if (($stationname eq "Jan Mayen") && $norec < 137980 
            && ($unixtime >= $corrclockjmstart && 
                $unixtime <= $corrclockjmend)) {
            $unixtime -= 3600*2;
        }
        $obstime .= $unixtime.",";
        $timestr_start = strftime("%Y-%m-%d %H:%M UTC",gmtime($unixtime)) if ($norec==5);
        $timestr_end = strftime("%Y-%m-%d %H:%M UTC",gmtime($unixtime));
        $nvalues = $tmparr[1];
        # Corrections at Bjørnøya
        if ($stationname eq "Bjørnøya") {
            if ($unixtime >= $invertbidlistart && $unixtime <= $invertbidliend && $tmparr[4] ne $misvalin) {
                $tmparr[4] *= -1;
            }
        }
        $qchit  = 0;
        for ($i =0; $i < $stationinfo{$stationname}{"quality_removals"};$i++) {
            if (($unixtime >
                    $stationinfo{$stationname}{"quality_keys"}{$i}{"start"}) && 
                ($unixtime <
                    $stationinfo{$stationname}{"quality_keys"}{$i}{"end"})) {
                $qchit = 1;
                #print "$norec $i [".strftime("%Y-%m-%d %H:%M UTC",gmtime($unixtime))."] $tmparr[2] - $tmparr[4] - $stationinfo{$stationname}{\"quality_keys\"}{$i}{\"par\"} - ";
                if ($stationinfo{$stationname}{"quality_keys"}{$i}{"par"} eq "ssi") {
                    $ssi .= $misvalout.",";
                    $ssitemp .= $tmparr[3].",";
                    $dli .= $tmparr[4].",";
                    $dlitemp .= $tmparr[5].",";
                    $battmin .= $tmparr[6].",";
                    last;
                } elsif ($stationinfo{$stationname}{"quality_keys"}{$i}{"par"} eq "dli") {
                    $ssi .= $tmparr[2].",";
                    $ssitemp .= $tmparr[3].",";
                    $dli .= $misvalout.",";
                    $dlitemp .= $tmparr[5].",";
                    $battmin .= $tmparr[6].",";
                    last;
                } else {
                    $ssi .= $misvalout.",";
                    $ssitemp .= $tmparr[3].",";
                    $dli .= $misvalout.",";
                    $dlitemp .= $tmparr[5].",";
                    $battmin .= $tmparr[6].",";
                    last;
                }
            }
        }
        next if ($qchit);
        $ssi .= $tmparr[2].",";
        $ssitemp .= $tmparr[3].",";
        $dli .= $tmparr[4].",";
        $dlitemp .= $tmparr[5].",";
        $battmin .= $tmparr[6].",";
    }
    ##warn "Data records: nvalues ($nvalues) and norec ($norec) differ\n" if ($nvalues != $norec-4);

    ###########################################################
    # Clean records
    #
    $obstime =~ s/,$//;
    $ssi =~ s/,$//;
    $ssi =~ s/$misvalin/$misvalout/g;
    $ssitemp =~ s/,$//;
    $ssitemp =~ s/$misvalin/$misvalout/g;
    $dli =~ s/,$//;
    $dli =~ s/$misvalin/$misvalout/g;
    $dlitemp =~ s/,$//;
    $dlitemp =~ s/$misvalin/$misvalout/g;
    $battmin =~ s/,$//;
    $battmin =~ s/$misvalin/$misvalout/g;

    ###########################################################
    # Enter values into the CDL template
    #
    s/\+history/$history/ for (@cdlout);
    s/\+title/$stationinfo{$stationname}{title}/ for (@cdlout);
    s/\+abstract/$stationinfo{$stationname}{abstract}/ for (@cdlout);
    s/\+pname/$stationinfo{$stationname}{product_name}/ for (@cdlout);
    s/\+projectname/$stationinfo{$stationname}{project_name}/ for (@cdlout);
    s/\+area/$stationinfo{$stationname}{area}/ for (@cdlout);
    s/\+topic/$topiccategory/ for (@cdlout);
    s/\+keyw/$keywords/ for (@cdlout);
    s/\+gcmdkeyw/$gcmdkeywords/ for (@cdlout);
    s/\+activity_type/$activitytype/ for (@cdlout);
    s/\+piname/$stationinfo{$stationname}{PI_name}/ for (@cdlout);
    s/\+inst/$stationinfo{$stationname}{institution}/ for (@cdlout);
    s/\+url/$stationinfo{$stationname}{url}/ for (@cdlout);
    s/\+email/$stationinfo{$stationname}{contact}/ for (@cdlout);
    s/\+distribution/$stationinfo{$stationname}{distribution_statement}/ for (@cdlout);
    s/\+qual/$stationinfo{$stationname}{quality_statement}/ for (@cdlout);
    s/\+lat/$stationinfo{$stationname}{lat}/ for (@cdlout);
    s/\+lon/$stationinfo{$stationname}{lon}/ for (@cdlout);
    s/\+stationid/$stationname/ for (@cdlout);
    s/\+time/$obstime/ for (@cdlout);
    s/\+start_date/$timestr_start/ for (@cdlout);
    s/\+stop_date/$timestr_end/ for (@cdlout);
    s/\+ssi/$ssi/ for (@cdlout);
    s/\+tempssi/$ssitemp/ for (@cdlout);
    s/\+dli/$dli/ for (@cdlout);
    s/\+tempdli/$dlitemp/ for (@cdlout);
    s/\+battmin/$battmin/ for (@cdlout);

    return(@cdlout);
}

#
# Decode and convert the NFH biological format containing sediment data.
# This is linked to template_biosediment.cdl
#
sub create_cdl_nfhbiosed {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@source,@mytmp,@mytmp1);
    my($title,$abstract,$topiccategory);
    my($southernmost_latitude,$northernmost_latitude);
    my($keywords,$variables,$units);
    my($westernmost_longitude,$easternmost_longitude,$start_date,$stop_date);
    my($institution,$url,$PI_name,$contact,$platform,$distribution_statement);
    my($quality_statement, $project_name);
    my($activity_type, $operational_status);
    my(@timearr,$timeunix,$timestr);
    my($line,$norec);
    my(@mytimes, @mydepths, $mydate, @mylatlonpair, $ll, $tz);
    my(%mydata, $sc, $lat, $lon, $z);
    my($chl, $chl_stdev, $pigm, $pigm_stdev, $fpc);
    my($pon, $pon_stdev, $poc, $poc_stdev);
    my($ndepths,$nstations,$match);
    #my $nfhbiovar = "latitude, longitude, time, date, sampling_depth, chl-a, phaeopigment, POC, PON";
    my $nfhbiovar = "date, time, latitude, longitude, sampling_depth, POC, stdev_POC, PON, stdev_PON, FPC, Chla, stdev_Chla, Phaeo, stdev_Phaeo";
    #my $nfhbiounits = "degrees_north, degrees_west, hours(hh:mm UTC), year_month_day, meter, ÃÂµg_chl-a_l-1, ÃÂµg_phaeo_l-1, mg_POC_m-3, mg_PON_m-3";
    my $nfhbiounits = "year_month_day, hours(hh:mm UTC), degrees_north, degrees_east, meter, mg_POC_m-2_d-1,  mg_POC_m-2_d-1,  mg_PON_m-2_d-1, mg_PON_m-2_d-1, mg_FPC_m-2_d-1, mg_Chla_m-2_d-1, mg_Chla_m-2_d-1, mg_Phaeo_m-2_d-1, mg_Phaeo_m-2_d-1";
    my $misvalin = -999;
    my $misvalout = 9999.;
    my $gcmdkeyw = "Oceans > Ocean Chemistry > Pigments\nOceans > Ocean Chemistry > Pigments > Chlorophyll\nOceans > Ocean Chemistry > Carbon\nOceans > Ocean Chemistry > Nitrogen";

    ###########################################################
    # Copy the template and the input stream
    @cdlout = @$tempref;
    @source = @$txtref;

    ########################################################### 
    # First the necessary global information is extracted from the input
    # data stream
    $title = (grep /#\s+title: /,@source)[0];
    $title =~ s/#\s+title:\s*//;
    $title =~ s/\s+$//;
    $abstract = (grep /#\s+abstract: /,@source)[0];
    $abstract =~ s/#\s+abstract:\s*//;
    $abstract =~ s/\s+$//;
    $topiccategory = (grep /#\s+topiccategory: /,@source)[0];
    $topiccategory =~ s/#\s+topiccategory:\s*//;
    $topiccategory =~ s/\s+$//;
    $keywords = (grep /#\s+keywords: /,@source)[0];
    $keywords =~ s/#\s+keywords:\s*//;
    $keywords =~ s/\s+$//;
    $activity_type = (grep /#\s+activity_type: /,@source)[0];
    $activity_type =~ s/#\s+activity_type:\s*//;
    $activity_type =~ s/\s+$//;
    $operational_status = (grep /#\s+operational_status: /,@source)[0];
    $operational_status =~ s/#\s+operational_status:\s*//;
    $operational_status =~ s/\s+$//;
    $area = (grep /#\s+area: /,@source)[0];
    $area =~ s/#\s+area:\s*//;
    $area =~ s/\s+$//;
    $southernmost_latitude = (grep /#\s+southernmost_latitude: /,@source)[0];
    $southernmost_latitude =~ s/#\s+southernmost_latitude:\s*//;
    $southernmost_latitude =~ s/\s+$//;
    $northernmost_latitude = (grep /#\s+northernmost_latitude: /,@source)[0];
    $northernmost_latitude =~ s/#\s+northernmost_latitude:\s*//;
    $northernmost_latitude =~ s/\s+$//;
    $westernmost_longitude = (grep /#\s+westernmost_longitude: /,@source)[0];
    $westernmost_longitude =~ s/#\s+westernmost_longitude:\s*//;
    $westernmost_longitude =~ s/\s+$//;
    $easternmost_longitude = (grep /#\s+easternmost_longitude: /,@source)[0];
    $easternmost_longitude =~ s/#\s+easternmost_longitude:\s*//;
    $easternmost_longitude =~ s/\s+$//;
    $start_date = (grep /#\s+start_date: /,@source)[0];
    $start_date =~ s/#\s+start_date:\s*//;
    $start_date =~ s/\s+$//;
    $stop_date = (grep /#\s+stop_date: /,@source)[0];
    $stop_date =~ s/#\s+stop_date:\s*//;
    $stop_date =~ s/\s+$//;
    $institution = (grep /#\s+institution: /,@source)[0];
    $institution =~ s/#\s+institution:\s*//;
    $institution =~ s/\s+$//;
    $url = (grep /#\s+url: /,@source)[0];
    $url =~ s/#\s+url:\s*//;
    $url =~ s/\s+$//;
    $PI_name = (grep /#\s+PI_name: /,@source)[0];
    $PI_name =~ s/#\s+PI_name:\s*//;
    $PI_name =~ s/\s+$//;
    $contact = (grep /#\s+contact: /,@source)[0];
    $contact =~ s/#\s+contact:\s*//;
    $contact =~ s/\s+$//;
    $distribution_statement = (grep /#\s+distribution_statement: /,@source)[0];
    $distribution_statement =~ s/#\s+distribution_statement:\s*//;
    $distribution_statement =~ s/\s+$//;
    $project_name = (grep /#\s+project_name: /,@source)[0];
    $project_name =~ s/#\s+project_name:\s*//;
    $project_name =~ s/\s+$//;
    $quality_statement = (grep /#\s+quality_statement: /,@source)[0];
    $quality_statement =~ s/#\s+quality_statement:\s*//;
    $quality_statement =~ s/\s+$//;
    $variables = (grep /#\s+variables: /,@source)[0];
    $variables =~ s/#\s+variables:\s*//;
    $variables =~ s/\s+$//;
    $units = (grep /#\s+units: /,@source)[0];
    $units =~ s/#\s+units:\s*//;
    $units =~ s/\s+$//;

    # Check that the file follows the expected outline
    unless ($variables eq $nfhbiovar){
        print ">>>$variables<<<\n";
        print ">>>$nfhbiovar<<<\n";
        die "Variables names does not match the expected" 
    }
    unless ($units eq $nfhbiounits){
        print ">>>$units<<<\n";
        print ">>>$nfhbiounits<<<\n";
        die "Units names does not match the expected" 
    }

    ########################################################### 
    # Then the actual data records are decoded and prepared for future use
    #
    foreach (@source) {
        next if m/^#/;
        ##next if ($_ =~ m/^\t\s+\n$/); 
        $_ =~ s/^\t//;
        $_ =~ s/\s+/ /g;
        #print "$_\n";
        $_ =~ s/$misvalin/$misvalout/g;
        @mytmp = split /\s+/,$_;
        $mydate = $mytmp[0]." ".$mytmp[1]." UTC";
        $tz = Date_TimeZone;
        unless ($tz eq "UTC") {
            $mydate = Date_ConvTZ(ParseDate($mydate),"$tz","UTC");
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        } else {
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        }
        unless (grep /$mydate/,@mytimes) {
            push @mytimes, $mydate; 
            $sc = 0;
        }
        $ll = $mytmp[2]." ".$mytmp[3];
        push @mydepths, $mytmp[4] unless grep /^$mytmp[4]$/,@mydepths;
        push @mylatlonpair, $ll unless grep /$ll/,@mylatlonpair;

        $mydata{$mydate}{"lat"} = $mytmp[2];
        $mydata{$mydate}{"lon"} = $mytmp[3];
        $mydata{$mydate}{"z"}[$sc] = $mytmp[4];
        $mydata{$mydate}{"POC"}[$sc] = $mytmp[5];
        $mydata{$mydate}{"POC_stdev"}[$sc] = $mytmp[6];
        $mydata{$mydate}{"PON"}[$sc] = $mytmp[7];
        $mydata{$mydate}{"PON_stdev"}[$sc] = $mytmp[8];
        $mydata{$mydate}{"FPC"}[$sc] = $mytmp[9];
        $mydata{$mydate}{"chl-a"}[$sc] = $mytmp[10];
        $mydata{$mydate}{"chl-a_stdev"}[$sc] = $mytmp[11];
        $mydata{$mydate}{"phaoepigment"}[$sc] = $mytmp[12];
        $mydata{$mydate}{"phaoepigment_stdev"}[$sc] = $mytmp[13];
        $mydata{$mydate}{"noobs"} = ($sc+1);
        $sc++;
    }

    ########################################################### 
    # Dump data into CDL template
    # Global attributes
    s/\+title/$title/ for (@cdlout); # Actually a global variabel
    s/\+abstract/$abstract/ for (@cdlout); # Actually a global variabel
    s/\+keyw/$keywords/ for (@cdlout); # Actually a global variabel
    s/\+gcmdkeyw/$gcmdkeyw/ for (@cdlout); # Actually a global variabel
    s/\+topic/$topiccategory/ for (@cdlout); # Actually a global variabel
    s/\+vessel/$vessel/ for (@cdlout); # Actually a global variabel
    s/\+slat/$southernmost_latitude/ for (@cdlout);
    s/\+nlat/$northernmost_latitude/ for (@cdlout);
    s/\+elon/$easternmost_longitude/ for (@cdlout);
    s/\+wlon/$westernmost_longitude/ for (@cdlout);
    s/\+start_date/$start_date/ for (@cdlout);
    s/\+stop_date/$stop_date/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+opstatus/$operational_status/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+url/$url/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+qual/$quality_statement/ for (@cdlout);
    s/\+project_name/$project_name/ for (@cdlout);
    #s/\+product_name/$product_name/ for (@cdlout);
    $ndepths = $#mydepths+1;
    s/\+ndepths/$ndepths/ for (@cdlout);
    $nstations = $#mylatlonpair+1;
    s/\+nstations/$nstations/ for (@cdlout);

    # Multi-dimensional array...
    foreach (sort(keys(%mydata))) {
        $timeunix .= UnixDate($_,"%s").",";
        $lat .= $mydata{$_}{lat}.",";
        $lon .= $mydata{$_}{lon}.",";
        foreach $z (sort {$a <=> $b} @mydepths) {
            $match = 0;
            for ($sc=0;$sc<$mydata{$_}{noobs};$sc++){ 
                if ($mydata{$_}{z}[$sc]==$z) {
                    $chl .= $mydata{$_}{'chl-a'}[$sc].",";
                    $chl_stdev .= $mydata{$_}{'chl-a_stdev'}[$sc].",";
                    $pigm .= $mydata{$_}{phaoepigment}[$sc].",";
                    $pigm_stdev .= $mydata{$_}{phaoepigment_stdev}[$sc].",";
                    $pon .= $mydata{$_}{PON}[$sc].",";
                    $pon_stdev .= $mydata{$_}{PON_stdev}[$sc].",";
                    $poc .= $mydata{$_}{POC}[$sc].",";
                    $poc_stdev .= $mydata{$_}{POC_stdev}[$sc].",";
                    $fpc .= $mydata{$_}{FPC}[$sc].",";
                    $match = 1;
                    last;
                }
            }
            unless ($match) {
                $chl .= "$misvalout,";
                $pigm .= "$misvalout,";
                $pon .= "$misvalout,";
                $poc .= "$misvalout,";
            }
        }
    }
    $z = join ",",sort({$a <=> $b} @mydepths);

    # Clean up records
    $timeunix =~ s/,$//;
    $z =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $chl =~ s/,$//;
    $chl_stdev =~ s/,$//;
    $pigm =~ s/,$//;
    $pigm_stdev =~ s/,$//;
    $pon =~ s/,$//;
    $pon_stdev =~ s/,$//;
    $poc =~ s/,$//;
    $poc_stdev =~ s/,$//;
    $fpc =~ s/,$//;

    # Dump to file
    s/\+time/$timeunix/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+depth/$z/ for (@cdlout);
    s/\+chl-a_stdev/$chl_stdev/ for (@cdlout);
    s/\+chl-a/$chl/ for (@cdlout);
    s/\+pigm_stdev/$pigm_stdev/ for (@cdlout);
    s/\+pigm/$pigm/ for (@cdlout);
    s/\+pon_stdev/$pon_stdev/ for (@cdlout);
    s/\+pon/$pon/ for (@cdlout);
    s/\+poc_stdev/$poc_stdev/ for (@cdlout);
    s/\+poc/$poc/ for (@cdlout);
    s/\+fpc/$fpc/ for (@cdlout);

    return(@cdlout);
}

#
# Decode and convert the NFH biological format containing biological data.
# This is linked to template_bio.cdl
#
sub create_cdl_nfhbio{
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@source,@mytmp,@mytmp1);
    my($title,$abstract,$topiccategory);
    my($southernmost_latitude,$northernmost_latitude);
    my($keywords,$variables,$units);
    my($westernmost_longitude,$easternmost_longitude,$start_date,$stop_date);
    my($institution,$url,$PI_name,$contact,$platform,$distribution_statement);
    my($quality_statement,$project_name);
    my($activity_type, $operational_status);
    my(@timearr,$timeunix,$timestr);
    my($line,$norec);
    my(@mystations, @mytimes, @mydepths, $mydate, @mylatlonpair, $ll, $tz);
    my(%mydata, $sc, $lat, $lon, $z, $stid);
    my($chl, $chl_stdev, $pigm, $pigm_stdev);
    my($no3no2, $no3no2_stdev, $po4, $po4_stdev, $sioh4, $sioh4_stdev);
    my($pon, $pon_stdev, $poc, $poc_stdev);
    my($ndepths,$nstations,$match);
    my $nfhbiovar = "CTD ID, date, time, latitude, longitude, sampling_depth, NO3+NO2, stdev_NO3+NO2, PO4, stdev_PO4, Si(OH)4, stdev_Si(OH)4, Chla, stdev_chla, Phaeo, stdev_Phaeo, POC, stdev_POC, PON, stdev_PON";
    my $nfhbiounits = "text, year_month_day, hours (hh:mm UTC), degrees_north, degrees_east, meter, µmol_L-1, µmol_L-1, µmol_L-1, µmol_L-1, µmol_L-1, µmol_L-1, µg_Chla_L-1, µg_Chla_L-1, µg_Phaeo_L-1, µg_Phaeo_L-1, µg_POC_L-1, µg_POC_L-1, µg_PON_L-1, µg_PON_L-1";
    my $misvalin = -999;
    my $misvalout = 9999.;
    my $gcmdkeyw = "Oceans > Ocean Chemistry > Pigments\nOceans > Ocean Chemistry > Pigments > Chlorophyll\nOceans > Ocean Chemistry > Carbon\nOceans > Ocean Chemistry > Nitrate\nOceans > Ocean Chemistry > Nitrite\nOceans > Ocean Chemistry > Phosphate\nOceans > Ocean Chemistry > Silicate\nOceans > Ocean Chemistry > Organic Carbon\nOceans > Ocean Chemistry > Organic Matter";

    ###########################################################
    # Copy the template and the input stream
    @cdlout = @$tempref;
    @source = @$txtref;

    ########################################################### 
    # First the necessary global information is extracted from the input
    # data stream
    $title = (grep /#\s+title: /,@source)[0];
    $title =~ s/#\s+title:\s*//;
    $title =~ s/\s+$//;
    $abstract = (grep /#\s+abstract: /,@source)[0];
    $abstract =~ s/#\s+abstract:\s*//;
    $abstract =~ s/\s+$//;
    $topiccategory = (grep /#\s+topiccategory: /,@source)[0];
    $topiccategory =~ s/#\s+topiccategory:\s*//;
    $topiccategory =~ s/\s+$//;
    $keywords = (grep /#\s+keywords: /,@source)[0];
    $keywords =~ s/#\s+keywords:\s*//;
    $keywords =~ s/\s+$//;
    $activity_type = (grep /#\s+activity_type: /,@source)[0];
    $activity_type =~ s/#\s+activity_type:\s*//;
    $activity_type =~ s/\s+$//;
    $operational_status = (grep /#\s+operational_status: /,@source)[0];
    $operational_status =~ s/#\s+operational_status:\s*//;
    $operational_status =~ s/\s+$//;
    $area = (grep /#\s+area: /,@source)[0];
    $area =~ s/#\s+area:\s*//;
    $area =~ s/\s+$//;
    $southernmost_latitude = (grep /#\s+southernmost_latitude: /,@source)[0];
    $southernmost_latitude =~ s/#\s+southernmost_latitude:\s*//;
    $southernmost_latitude =~ s/\s+$//;
    $northernmost_latitude = (grep /#\s+northernmost_latitude: /,@source)[0];
    $northernmost_latitude =~ s/#\s+northernmost_latitude:\s*//;
    $northernmost_latitude =~ s/\s+$//;
    $westernmost_longitude = (grep /#\s+westernmost_longitude: /,@source)[0];
    $westernmost_longitude =~ s/#\s+westernmost_longitude:\s*//;
    $westernmost_longitude =~ s/\s+$//;
    $easternmost_longitude = (grep /#\s+easternmost_longitude: /,@source)[0];
    $easternmost_longitude =~ s/#\s+easternmost_longitude:\s*//;
    $easternmost_longitude =~ s/\s+$//;
    $start_date = (grep /#\s+start_date: /,@source)[0];
    $start_date =~ s/#\s+start_date:\s*//;
    $start_date =~ s/\s+$//;
    $stop_date = (grep /#\s+stop_date: /,@source)[0];
    $stop_date =~ s/#\s+stop_date:\s*//;
    $stop_date =~ s/\s+$//;
    $institution = (grep /#\s+institution: /,@source)[0];
    $institution =~ s/#\s+institution:\s*//;
    $institution =~ s/\s+$//;
    $url = (grep /#\s+url: /,@source)[0];
    $url =~ s/#\s+url:\s*//;
    $url =~ s/\s+$//;
    $PI_name = (grep /#\s+PI_name: /,@source)[0];
    $PI_name =~ s/#\s+PI_name:\s*//;
    $PI_name =~ s/\s+$//;
    $contact = (grep /#\s+contact: /,@source)[0];
    $contact =~ s/#\s+contact:\s*//;
    $contact =~ s/\s+$//;
    $distribution_statement = (grep /#\s+distribution_statement: /,@source)[0];
    $distribution_statement =~ s/#\s+distribution_statement:\s*//;
    $distribution_statement =~ s/\s+$//;
    $project_name = (grep /#\s+project_name: /,@source)[0];
    $project_name =~ s/#\s+project_name:\s*//;
    $project_name =~ s/\s+$//;
    $quality_statement = (grep /#\s+quality_statement: /,@source)[0];
    $quality_statement =~ s/#\s+quality_statement:\s*//;
    $quality_statement =~ s/\s+$//;
    $variables = (grep /#\s+variables: /,@source)[0];
    $variables =~ s/#\s+variables:\s*//;
    $variables =~ s/\s+$//;
    $units = (grep /#\s+units: /,@source)[0];
    $units =~ s/#\s+units:\s*//;
    $units =~ s/\s+$//;

    # Check that the file follows the expected outline
    unless ($variables eq $nfhbiovar){
        print ">>>$variables<<<\n";
        print ">>>$nfhbiovar<<<\n";
        die "Variables names does not match the expected" 
    }
    unless ($units eq $nfhbiounits){
        print ">>>$units<<<\n";
        print ">>>$nfhbiounits<<<\n";
        die "Units names does not match the expected" 
    }

    ########################################################### 
    # Then the actual data records are decoded and prepared for future use
    #
    foreach (@source) {
        next if m/^#/;
        ##next if ($_ =~ m/^\t\s+\n$/); 
        $_ =~ s/^\t//;
        $_ =~ s/\s+/ /g;
        #print "$_\n";
        $_ =~ s/$misvalin/$misvalout/g;
        @mytmp = split /\s+/,$_;
        $mydate = $mytmp[1]." ".$mytmp[2]." UTC";
        $tz = Date_TimeZone;
        unless ($tz eq "UTC") {
            $mydate = Date_ConvTZ(ParseDate($mydate),"$tz","UTC");
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        } else {
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        }
        unless (grep /$mydate/,@mytimes) {
            push @mytimes, $mydate; 
            $sc = 0;
        }
        $ll = $mytmp[3]." ".$mytmp[4];
        push @mydepths, $mytmp[5] unless grep /^$mytmp[5]$/,@mydepths;
        push @mylatlonpair, $ll unless grep /$ll/,@mylatlonpair;

        $mydata{$mydate}{"stid"} = $mytmp[0];
        $mydata{$mydate}{"lat"} = $mytmp[3];
        $mydata{$mydate}{"lon"} = $mytmp[4];
        $mydata{$mydate}{"z"}[$sc] = $mytmp[5];
        $mydata{$mydate}{"no3no2"}[$sc] = $mytmp[6];
        $mydata{$mydate}{"no3no2_stdev"}[$sc] = $mytmp[7];
        $mydata{$mydate}{"PO4"}[$sc] = $mytmp[8];
        $mydata{$mydate}{"PO4_stdev"}[$sc] = $mytmp[9];
        $mydata{$mydate}{"sioh4"}[$sc] = $mytmp[10];
        $mydata{$mydate}{"sioh4_stdev"}[$sc] = $mytmp[11];
        $mydata{$mydate}{"chl-a"}[$sc] = $mytmp[12];
        $mydata{$mydate}{"chl-a_stdev"}[$sc] = $mytmp[13];
        $mydata{$mydate}{"phaoepigment"}[$sc] = $mytmp[14];
        $mydata{$mydate}{"phaoepigment_stdev"}[$sc] = $mytmp[15];
        $mydata{$mydate}{"POC"}[$sc] = $mytmp[16];
        $mydata{$mydate}{"POC_stdev"}[$sc] = $mytmp[17];
        $mydata{$mydate}{"PON"}[$sc] = $mytmp[18];
        $mydata{$mydate}{"PON_stdev"}[$sc] = $mytmp[19];
        $mydata{$mydate}{"noobs"} = ($sc+1);
        $sc++;
    }

    ########################################################### 
    # Dump data into CDL template
    # Global attributes
    s/\+title/$title/ for (@cdlout); # Actually a global variabel
    s/\+abstract/$abstract/ for (@cdlout); # Actually a global variabel
    s/\+keyw/$keywords/ for (@cdlout); # Actually a global variabel
    s/\+gcmdkeyw/$gcmdkeyw/ for (@cdlout); # Actually a global variabel
    s/\+topic/$topiccategory/ for (@cdlout); # Actually a global variabel
    s/\+vessel/$vessel/ for (@cdlout); # Actually a global variabel
    s/\+slat/$southernmost_latitude/ for (@cdlout);
    s/\+nlat/$northernmost_latitude/ for (@cdlout);
    s/\+elon/$easternmost_longitude/ for (@cdlout);
    s/\+wlon/$westernmost_longitude/ for (@cdlout);
    s/\+start_date/$start_date/ for (@cdlout);
    s/\+stop_date/$stop_date/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+opstatus/$operational_status/ for (@cdlout);
    s/\+area/$area/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+url/$url/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+qual/$quality_statement/ for (@cdlout);
    s/\+project_name/$project_name/ for (@cdlout);
    #s/\+product_name/$product_name/ for (@cdlout);
    $ndepths = $#mydepths+1;
    s/\+ndepths/$ndepths/ for (@cdlout);
    $nstations = $#mylatlonpair+1;
    s/\+nstations/$nstations/ for (@cdlout);

    # Multi-dimensional array...
    foreach (sort(keys(%mydata))) {
        $timeunix .= UnixDate($_,"%s").",";
        $lat .= $mydata{$_}{lat}.",";
        $lon .= $mydata{$_}{lon}.",";
        $stid .= "\"".$mydata{$_}{stid}."\"".",";
        foreach $z (sort {$a <=> $b} @mydepths) {
            $match = 0;
            for ($sc=0;$sc<$mydata{$_}{noobs};$sc++){ 
                if ($mydata{$_}{z}[$sc]==$z) {
                    $no3no2 .= $mydata{$_}{'no3no2'}[$sc].",";
                    $no3no2_stdev .= $mydata{$_}{'no3no2_stdev'}[$sc].",";
                    $po4 .= $mydata{$_}{'PO4'}[$sc].",";
                    $po4_stdev .= $mydata{$_}{'PO4_stdev'}[$sc].",";
                    $sioh4 .= $mydata{$_}{'sioh4'}[$sc].",";
                    $sioh4_stdev .= $mydata{$_}{'sioh4_stdev'}[$sc].",";
                    $chl .= $mydata{$_}{'chl-a'}[$sc].",";
                    $chl_stdev .= $mydata{$_}{'chl-a_stdev'}[$sc].",";
                    $pigm .= $mydata{$_}{phaoepigment}[$sc].",";
                    $pigm_stdev .= $mydata{$_}{phaoepigment_stdev}[$sc].",";
                    $pon .= $mydata{$_}{PON}[$sc].",";
                    $pon_stdev .= $mydata{$_}{PON_stdev}[$sc].",";
                    $poc .= $mydata{$_}{POC}[$sc].",";
                    $poc_stdev .= $mydata{$_}{POC_stdev}[$sc].",";
                    $match = 1;
                    last;
                }
            }
            unless ($match) {
                $no3no2 .= "$misvalout,";
                $no3no2_stdev .= "$misvalout,";
                $po4 .= "$misvalout,";
                $po4_stdev .= "$misvalout,";
                $sioh4 .= "$misvalout,";
                $sioh4_stdev .= "$misvalout,";
                $chl .= "$misvalout,";
                $chl_stdev .= "$misvalout,";
                $pigm .= "$misvalout,";
                $pigm_stdev .= "$misvalout,";
                $pon .= "$misvalout,";
                $pon_stdev .= "$misvalout,";
                $poc .= "$misvalout,";
                $poc_stdev .= "$misvalout,";
            }
        }
    }
    $z = join ",",sort({$a <=> $b} @mydepths);

    # Clean up records
    $stid =~ s/,$//;
    $timeunix =~ s/,$//;
    $z =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $no3no2 =~ s/,$//;
    $no3no2_stdev =~ s/,$//;
    $po4 =~ s/,$//;
    $po4_stdev =~ s/,$//;
    $sioh4 =~ s/,$//;
    $sioh4_stdev =~ s/,$//;
    $chl =~ s/,$//;
    $chl_stdev =~ s/,$//;
    $pigm =~ s/,$//;
    $pigm_stdev =~ s/,$//;
    $pon =~ s/,$//;
    $pon_stdev =~ s/,$//;
    $poc =~ s/,$//;
    $poc_stdev =~ s/,$//;

    # Dump to file
    s/\+stid/$stid/ for (@cdlout);
    s/\+time/$timeunix/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+depth/$z/ for (@cdlout);
    s/\+no3no2_stdev/$no3no2_stdev/ for (@cdlout);
    s/\+no3no2/$no3no2/ for (@cdlout);
    s/\+po4_stdev/$po4_stdev/ for (@cdlout);
    s/\+po4/$po4/ for (@cdlout);
    s/\+sioh4_stdev/$sioh4_stdev/ for (@cdlout);
    s/\+sioh4/$sioh4/ for (@cdlout);
    s/\+chl-a_stdev/$chl_stdev/ for (@cdlout);
    s/\+chl-a/$chl/ for (@cdlout);
    s/\+pigm_stdev/$pigm_stdev/ for (@cdlout);
    s/\+pigm/$pigm/ for (@cdlout);
    s/\+pon_stdev/$pon_stdev/ for (@cdlout);
    s/\+pon/$pon/ for (@cdlout);
    s/\+poc_stdev/$poc_stdev/ for (@cdlout);
    s/\+poc/$poc/ for (@cdlout);

    return(@cdlout);
}
#
#
# Decode and convert the NFH biological format containing biological data.
# This is linked to template_biomassmeso.cdl
# This data is based upon integration over a water column and the date and
# time is used for identification.
#
sub create_cdl_nfhbiomass{
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@source,@mytmp,@mytmp1);
    my($title,$abstract,$topiccategory);
    my($southernmost_latitude,$northernmost_latitude);
    my($keywords,$variables,$units);
    my($westernmost_longitude,$easternmost_longitude,$start_date,$stop_date);
    my($institution,$url,$PI_name,$contact,$platform,$distribution_statement);
    my($quality_statement,$project_name);
    my($activity_type, $operational_status);
    my(@timearr,$timeunix,$timestr);
    my($line,$norec);
    my(@mystations, @mytimes, @mydepths, $mydate, @mylatlonpair, $ll, $tz);
    my(%mydata, $sc, $lat, $lon, $z, $stid);
    my($biomass);
    my($ndepths,$nstations,$match);
    my $nfhbiovar = "CTD ID, date, time, latitude, longitude, sampling_depth, integrated mesozooplankton biomass";
    my $nfhbiounits = "text, year_month_day, hours (hh:mm UTC), degrees_north, degrees_east, meter, mg_Carbon_m-2";
    my $misvalin = -999;
    my $misvalout = 9999.;
    my $gcmdkeyw = "Biosphere > Aquatic Ecosystems > Plankton > Zooplankton";

    ###########################################################
    # Copy the template and the input stream
    @cdlout = @$tempref;
    @source = @$txtref;

    ########################################################### 
    # First the necessary global information is extracted from the input
    # data stream
    $title = (grep /#\s+title: /,@source)[0];
    $title =~ s/#\s+title:\s*//;
    $title =~ s/\s+$//;
    $abstract = (grep /#\s+abstract: /,@source)[0];
    $abstract =~ s/#\s+abstract:\s*//;
    $abstract =~ s/\s+$//;
    $topiccategory = (grep /#\s+topiccategory: /,@source)[0];
    $topiccategory =~ s/#\s+topiccategory:\s*//;
    $topiccategory =~ s/\s+$//;
    $keywords = (grep /#\s+keywords: /,@source)[0];
    $keywords =~ s/#\s+keywords:\s*//;
    $keywords =~ s/\s+$//;
    $activity_type = (grep /#\s+activity_type: /,@source)[0];
    $activity_type =~ s/#\s+activity_type:\s*//;
    $activity_type =~ s/\s+$//;
    $operational_status = (grep /#\s+operational_status: /,@source)[0];
    $operational_status =~ s/#\s+operational_status:\s*//;
    $operational_status =~ s/\s+$//;
    $area = (grep /#\s+area: /,@source)[0];
    $area =~ s/#\s+area:\s*//;
    $area =~ s/\s+$//;
    $southernmost_latitude = (grep /#\s+southernmost_latitude: /,@source)[0];
    $southernmost_latitude =~ s/#\s+southernmost_latitude:\s*//;
    $southernmost_latitude =~ s/\s+$//;
    $northernmost_latitude = (grep /#\s+northernmost_latitude: /,@source)[0];
    $northernmost_latitude =~ s/#\s+northernmost_latitude:\s*//;
    $northernmost_latitude =~ s/\s+$//;
    $westernmost_longitude = (grep /#\s+westernmost_longitude: /,@source)[0];
    $westernmost_longitude =~ s/#\s+westernmost_longitude:\s*//;
    $westernmost_longitude =~ s/\s+$//;
    $easternmost_longitude = (grep /#\s+easternmost_longitude: /,@source)[0];
    $easternmost_longitude =~ s/#\s+easternmost_longitude:\s*//;
    $easternmost_longitude =~ s/\s+$//;
    $start_date = (grep /#\s+start_date: /,@source)[0];
    $start_date =~ s/#\s+start_date:\s*//;
    $start_date =~ s/\s+$//;
    $stop_date = (grep /#\s+stop_date: /,@source)[0];
    $stop_date =~ s/#\s+stop_date:\s*//;
    $stop_date =~ s/\s+$//;
    $institution = (grep /#\s+institution: /,@source)[0];
    $institution =~ s/#\s+institution:\s*//;
    $institution =~ s/\s+$//;
    $url = (grep /#\s+url: /,@source)[0];
    $url =~ s/#\s+url:\s*//;
    $url =~ s/\s+$//;
    $PI_name = (grep /#\s+PI_name: /,@source)[0];
    $PI_name =~ s/#\s+PI_name:\s*//;
    $PI_name =~ s/\s+$//;
    $contact = (grep /#\s+contact: /,@source)[0];
    $contact =~ s/#\s+contact:\s*//;
    $contact =~ s/\s+$//;
    $distribution_statement = (grep /#\s+distribution_statement: /,@source)[0];
    $distribution_statement =~ s/#\s+distribution_statement:\s*//;
    $distribution_statement =~ s/\s+$//;
    $project_name = (grep /#\s+project_name: /,@source)[0];
    $project_name =~ s/#\s+project_name:\s*//;
    $project_name =~ s/\s+$//;
    $quality_statement = (grep /#\s+quality_statement: /,@source)[0];
    $quality_statement =~ s/#\s+quality_statement:\s*//;
    $quality_statement =~ s/\s+$//;
    $variables = (grep /#\s+variables: /,@source)[0];
    $variables =~ s/#\s+variables:\s*//;
    $variables =~ s/\s+$//;
    $units = (grep /#\s+units: /,@source)[0];
    $units =~ s/#\s+units:\s*//;
    $units =~ s/\s+$//;

    # Check that the file follows the expected outline
    unless ($variables eq $nfhbiovar){
        print ">>>$variables<<<\n";
        print ">>>$nfhbiovar<<<\n";
        die "Variables names does not match the expected" 
    }
    unless ($units eq $nfhbiounits){
        print ">>>$units<<<\n";
        print ">>>$nfhbiounits<<<\n";
        die "Units names does not match the expected" 
    }

    ########################################################### 
    # Then the actual data records are decoded and prepared for future use
    #
    foreach (@source) {
        next if m/^#/;
        ##next if ($_ =~ m/^\t\s+\n$/); 
        $_ =~ s/^\t//;
        $_ =~ s/\s+/ /g;
        #print "$_\n";
        $_ =~ s/$misvalin/$misvalout/g;
        @mytmp = split /\s+/,$_;
        $mydate = $mytmp[1]." ".$mytmp[2]." UTC";
        $tz = Date_TimeZone;
        unless ($tz eq "UTC") {
            $mydate = Date_ConvTZ(ParseDate($mydate),"$tz","UTC");
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        } else {
            $mydate = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        }
        unless (grep /$mydate/,@mytimes) {
            push @mytimes, $mydate; 
            $sc = 0;
        }
        $ll = $mytmp[3]." ".$mytmp[4];
        push @mydepths, $mytmp[5] unless grep /^$mytmp[5]$/,@mydepths;
        push @mylatlonpair, $ll unless grep /$ll/,@mylatlonpair;

        $mydata{$mydate}{"stid"} = $mytmp[0];
        $mydata{$mydate}{"lat"} = $mytmp[3];
        $mydata{$mydate}{"lon"} = $mytmp[4];
        $mydata{$mydate}{"z"} = $mytmp[5];
        $mydata{$mydate}{"biomass"} = $mytmp[6];
        $mydata{$mydate}{"noobs"} = ($sc+1);
        $sc++;
    }

    ########################################################### 
    # Dump data into CDL template
    # Global attributes
    s/\+title/$title/ for (@cdlout); # Actually a global variabel
    s/\+abstract/$abstract/ for (@cdlout); # Actually a global variabel
    s/\+keyw/$keywords/ for (@cdlout); # Actually a global variabel
    s/\+gcmdkeyw/$gcmdkeyw/ for (@cdlout); # Actually a global variabel
    s/\+topic/$topiccategory/ for (@cdlout); # Actually a global variabel
    s/\+vessel/$vessel/ for (@cdlout); # Actually a global variabel
    s/\+slat/$southernmost_latitude/ for (@cdlout);
    s/\+nlat/$northernmost_latitude/ for (@cdlout);
    s/\+elon/$easternmost_longitude/ for (@cdlout);
    s/\+wlon/$westernmost_longitude/ for (@cdlout);
    s/\+start_date/$start_date/ for (@cdlout);
    s/\+stop_date/$stop_date/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+opstatus/$operational_status/ for (@cdlout);
    s/\+area/$area/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+url/$url/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+qual/$quality_statement/ for (@cdlout);
    s/\+project_name/$project_name/ for (@cdlout);
    #s/\+product_name/$product_name/ for (@cdlout);
    $ndepths = $#mydepths+1;
    s/\+ndepths/$ndepths/ for (@cdlout);
    $nstations = $#mylatlonpair+1;
    s/\+nstations/$nstations/ for (@cdlout);

    # Multi-dimensional array...
    foreach (sort(keys(%mydata))) {
        $timeunix .= UnixDate($_,"%s").",";
        $lat .= $mydata{$_}{lat}.",";
        $lon .= $mydata{$_}{lon}.",";
        $z .= $mydata{$_}{z}.",";
        $stid .= "\"".$mydata{$_}{stid}."\"".",";
        $biomass .= $mydata{$_}{'biomass'}.",";
    }

    # Clean up records
    $stid =~ s/,$//;
    $timeunix =~ s/,$//;
    $z =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $biomass =~ s/,$//;

    # Dump to file
    s/\+stid/$stid/ for (@cdlout);
    s/\+time/$timeunix/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    s/\+depth/$z/ for (@cdlout);
    s/\+biomass/$biomass/ for (@cdlout);

    return(@cdlout);
}

#
# Decode and convert the UGOT CTD format.
# This is linked to template_ctd_ugot.cdl
# It is assumed (due to experience) that files are delivered in UTF-8
# encoding and thus have to be decoded.
#
# This function use a single template and removes fields not used with
# some of the datasets delivered.
#
# This should be rewritten in the future to generate one file per cast
# which makes it easier to download the data needed when the shopping
# basket works, it also saves disk...
#
sub create_cdl_ugotctd {
    my(@cdlout,@tmparr);
    my($tempref,$txtref) = @_;
    my(@source,@mytmp,@mytmp1);
    my($title,$abstract,$topiccategory);
    my($southernmost_latitude,$northernmost_latitude);
    my($keywords,$variables,$units);
    my($westernmost_longitude,$easternmost_longitude,$start_date,$stop_date);
    my($institution,$url,$PI_name,$contact,$platform,$distribution_statement);
    my($quality_statement, $project_name, $product_name);
    my($activity_type, $operational_status);
    my(@timearr,$timeunix,$timestr);
    my($line,$norec, $filetype);
    my(@mytimes, @mystations, @mydepths, @mypres, $mydate, @mylatlonpair);
    my($ll, $tz);
    my(%mydata, $sc, $lat, $lon, $z);
    my($stid, $pres, $turb, $temp, $psal);
    my($pres_qf, $turb_qf, $temp_qf, $psal_qf);
    my($ndepths,$nstations,$nrecords,$match);
    my $ugotvars1 = "Cruise, Station, Type, mon/day/yr, hh:mm, Longitude, Latitude, Bottom_Depth, Pressure, QF, Temperature_[ITS-90], QF, WET-Labs_ECO_NTU, QF, Salinity, QF";
    my $ugotvars2 = "Cruise, Station, mon/day/yr, hh:mm_[UTC], Longitude, Latitude, Pressure, QF, Temperature_[ITS-90], QF, Salinity, QF";
    my $ugotunits1 = "No_unit, No_unit, No_unit, month/day/year, hour:minutes, degrees_east, degrees_north, meter, deci_bar, No_unit, degrees_C, No_unit, volts, No_unit, PSU, No_unit";
    my $ugotunits2 = "No_unit, No_unit, month/day/year, hour:minutes, degrees_east, degrees_north, deci_bar, No_unit, degrees_C, No_unit, PSU, No_unit";
    my $misvalin = -999;
    my $misvalout = 9999.;
    my $gcmdkeyw = "???";

    ###########################################################
    # Copy the template and the input stream
    @cdlout = @$tempref;
    @source = @$txtref;

    ########################################################### 
    # First the necessary global information is extracted from the input
    # data stream
    $title = (grep /#\s+title: /,@source)[0];
    $title =~ s/#\s+title:\s*//;
    $title =~ s/\s+$//;
    $abstract = (grep /#\s+abstract: /,@source)[0];
    $abstract =~ s/#\s+abstract:\s*//;
    $abstract =~ s/\s+$//;
    $topiccategory = (grep /#\s+topiccategory: /,@source)[0];
    $topiccategory =~ s/#\s+topiccategory:\s*//;
    $topiccategory =~ s/\s+$//;
    $keywords = (grep /#\s+keywords: /,@source)[0];
    $keywords =~ s/#\s+keywords:\s*//;
    $keywords =~ s/\s+$//;
    $gcmdkeyw = (grep /#\s+gcmd_keywords: /,@source)[0];
    $gcmdkeyw =~ s/#\s+gcmd_keywords:\s*//;
    $gcmdkeyw =~ s/\s+$//;
    $gcmdkeyw =~ s/,/\n/g;
    $activity_type = (grep /#\s+activity_type: /,@source)[0];
    $activity_type =~ s/#\s+activity_type:\s*//;
    $activity_type =~ s/\s+$//;
    $operational_status = (grep /#\s+operational_status: /,@source)[0];
    $operational_status =~ s/#\s+operational_status:\s*//;
    $operational_status =~ s/\s+$//;
    $area = (grep /#\s+area: /,@source)[0];
    $area =~ s/#\s+area:\s*//;
    $area =~ s/\s+$//;
    $southernmost_latitude = (grep /#\s+southernmost_latitude: /,@source)[0];
    $southernmost_latitude =~ s/#\s+southernmost_latitude:\s*//;
    $southernmost_latitude =~ s/\s+$//;
    $northernmost_latitude = (grep /#\s+northernmost_latitude: /,@source)[0];
    $northernmost_latitude =~ s/#\s+northernmost_latitude:\s*//;
    $northernmost_latitude =~ s/\s+$//;
    $westernmost_longitude = (grep /#\s+westernmost_longitude: /,@source)[0];
    $westernmost_longitude =~ s/#\s+westernmost_longitude:\s*//;
    $westernmost_longitude =~ s/\s+$//;
    $easternmost_longitude = (grep /#\s+easternmost_longitude: /,@source)[0];
    $easternmost_longitude =~ s/#\s+easternmost_longitude:\s*//;
    $easternmost_longitude =~ s/\s+$//;
    $start_date = (grep /#\s+start_date: /,@source)[0];
    $start_date =~ s/#\s+start_date:\s*//;
    $start_date =~ s/\s+$//;
    $stop_date = (grep /#\s+stop_date: /,@source)[0];
    $stop_date =~ s/#\s+stop_date:\s*//;
    $stop_date =~ s/\s+$//;
    $institution = (grep /#\s+institution: /,@source)[0];
    $institution =~ s/#\s+institution:\s*//;
    $institution =~ s/\s+$//;
    $url = (grep /#\s+url: /,@source)[0];
    $url =~ s/#\s+url:\s*//;
    $url =~ s/\s+$//;
    $PI_name = (grep /#\s+PI_name: /,@source)[0];
    $PI_name =~ s/#\s+PI_name:\s*//;
    $PI_name =~ s/\s+$//;
    $contact = (grep /#\s+contact: /,@source)[0];
    $contact =~ s/#\s+contact:\s*//;
    $contact =~ s/\s+$//;
    $distribution_statement = (grep /#\s+distribution_statement: /,@source)[0];
    $distribution_statement =~ s/#\s+distribution_statement:\s*//;
    $distribution_statement =~ s/\s+$//;
    $project_name = (grep /#\s+project_name: /,@source)[0];
    $project_name =~ s/#\s+project_name:\s*//;
    $project_name =~ s/\s+$//;
    $quality_statement = (grep /#\s+quality_statement: /,@source)[0];
    $quality_statement =~ s/#\s+quality_statement:\s*//;
    $quality_statement =~ s/\s+$//;
    $variables = (grep /#\s+variables: /,@source)[0];
    $variables =~ s/#\s+variables:\s*//;
    $variables =~ s/\s+$//;
    $units = (grep /#\s+units: /,@source)[0];
    $units =~ s/#\s+units:\s*//;
    $units =~ s/\s+$//;

    # Check that the file follows the expected outline
    if ($variables eq $ugotvars1){
        $filetype = "ISSS08";
    } elsif ($variables eq $ugotvars2) {
        $filetype = "LOMROG07";
        foreach (@cdlout) {
            push @mytmp, $_ unless m/(turb)|(turb_qf)|(bdepth)/;
        }
        @cdlout = @mytmp;
        undef @mytmp;
    } else {
        print "\n";
        print "Incorrect variables...\n";
        print "Found: $variables\n";
        print "Supported: $ugotvars1\n";
        print "Supported: $ugotvars2\n";
        die "Variables names does not match the expected" 
    }
    unless ($units eq $ugotunits1 || $units eq $ugotunits2) {
        print "Found: $units\n";
        print "Supported: $ugotunits1\n";
        print "Supported: $ugotunits2\n";
        die "Units does not match the expected" 
    }

    ########################################################### 
    # Then the actual data records are decoded and prepared for future use
    #
    $tz = Date_TimeZone;
    print " This computer runs in timezone: $tz\n";
    $nrecords = 0;
    undef @mytimes;
    foreach (@source) {
        $line = decode_utf8($_);
        next if ($line =~ m/^#/);
        next if ($line =~ m/^\s+$/);
        $line =~ s/^\s//;
        $line =~ s/\s+/ /g;
        $line =~ s/$misvalin/$misvalout/g;
        @mytmp = split /\s+/,$line;
        if ($filetype eq "ISSS08") {
            $mydate = $mytmp[3]." ".$mytmp[4]." UTC";
        } else {
            $mydate = $mytmp[2]." ".$mytmp[3]." UTC";
        }
        if ($tz eq "UTC") {
            $timeunix = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        } else {
            $mydate = Date_ConvTZ(ParseDate($mydate),"$tz","UTC");
            $timeunix = UnixDate($mydate,"%Y-%m-%d %H:%M UTC");
        }
        unless (grep /$timeunix/,@mytimes) {
            push @mytimes, $timeunix; 
            $sc = 0;
        }
        if ($filetype eq "ISSS08") {
            $ll = $mytmp[6]." ".$mytmp[5];
            $mydata{$mydate}{"lat"} = $mytmp[6];
            $mydata{$mydate}{"lon"} = $mytmp[5];
            push @mypres, $mytmp[8] unless grep /^$mytmp[8]$/,@mypres;
            $mydata{$mydate}{"z"} = $mytmp[7];
            $mydata{$mydate}{"p"}[$sc] = $mytmp[8];
            $mydata{$mydate}{"p_qf"}[$sc] = $mytmp[9];
            $mydata{$mydate}{"t"}[$sc] = $mytmp[10];
            $mydata{$mydate}{"t_qf"}[$sc] = $mytmp[11];
            $mydata{$mydate}{"wl"}[$sc] = $mytmp[12];
            $mydata{$mydate}{"wl_qf"}[$sc] = $mytmp[13];
            $mydata{$mydate}{"s"}[$sc] = $mytmp[14];
            $mydata{$mydate}{"s_qf"}[$sc] = $mytmp[15];
        } else {
            $ll = $mytmp[5]." ".$mytmp[4];
            $mydata{$mydate}{"lat"} = $mytmp[5];
            $mydata{$mydate}{"lon"} = $mytmp[4];
            push @mypres, $mytmp[6] unless grep /^$mytmp[6]$/,@mypres;
            $mydata{$mydate}{"p"}[$sc] = $mytmp[6];
            $mydata{$mydate}{"p_qf"}[$sc] = $mytmp[7];
            $mydata{$mydate}{"t"}[$sc] = $mytmp[8];
            $mydata{$mydate}{"t_qf"}[$sc] = $mytmp[9];
            $mydata{$mydate}{"s"}[$sc] = $mytmp[10];
            $mydata{$mydate}{"s_qf"}[$sc] = $mytmp[11];
        }
        push @mylatlonpair, $ll unless grep /$ll/,@mylatlonpair;
        push @mystations, $mytmp[1] unless grep /^$mytmp[1]$/,@mystations;

        $mydata{$mydate}{"noobs"} = ($sc+1);
        $sc++;
        $nrecords++;
    }
    $nrecords += 1;
    print " $nrecords data records processed...\n";
    undef $timeunix;

    ########################################################### 
    # Dump data into CDL template
    # Global attributes
    s/\+title/$title/ for (@cdlout); # Actually a global variabel
    s/\+abstract/$abstract/ for (@cdlout); # Actually a global variabel
    s/\+keyw/$keywords/ for (@cdlout); # Actually a global variabel
    s/\+gcmdkeyw/$gcmdkeyw/ for (@cdlout); # Actually a global variabel
    s/\+topic/$topiccategory/ for (@cdlout); # Actually a global variabel
    s/\+vessel/$vessel/ for (@cdlout); # Actually a global variabel
    s/\+slat/$southernmost_latitude/ for (@cdlout);
    s/\+nlat/$northernmost_latitude/ for (@cdlout);
    s/\+elon/$easternmost_longitude/ for (@cdlout);
    s/\+wlon/$westernmost_longitude/ for (@cdlout);
    s/\+start_date/$start_date/ for (@cdlout);
    s/\+stop_date/$stop_date/ for (@cdlout);
    s/\+activity/$activity_type/ for (@cdlout);
    s/\+opstatus/$operational_status/ for (@cdlout);
    s/\+inst/$institution/ for (@cdlout);
    s/\+piname/$PI_name/ for (@cdlout);
    s/\+email/$contact/ for (@cdlout);
    s/\+url/$url/ for (@cdlout);
    s/\+distribution/$distribution_statement/ for (@cdlout);
    s/\+qual/$quality_statement/ for (@cdlout);
    s/\+project_name/$project_name/ for (@cdlout);
    s/\+product_name/$product_name/ for (@cdlout);
    #$ndepths = $#mydepths+1;
    $ndepths = $#mypres+1;
    s/\+ndepths/$ndepths/ for (@cdlout);
    $nstations = $#mylatlonpair+1;
    s/\+nstations/$nstations/ for (@cdlout);

    # Multi-dimensional array...
    # The search performed below is not efficient, but it works for the
    # datasets processed so far, especially since they are not too large.
    foreach (sort(keys(%mydata))) {
        $timeunix .= UnixDate($_,"%s").",";
        $lat .= $mydata{$_}{lat}.",";
        $lon .= $mydata{$_}{lon}.",";
        if ($filetype eq "ISSS08") {
            $z .= $mydata{$_}{z}.",";
        }
        foreach $pres (sort {$a <=> $b} @mypres) {
            $match = 0;
            for ($sc=0;$sc<$mydata{$_}{noobs};$sc++){ 
                if ($mydata{$_}{p}[$sc]==$pres) {
                    $temp .= $mydata{$_}{'t'}[$sc].",";
                    $temp_qf .= $mydata{$_}{'t_qf'}[$sc].",";
                    if ($filetype eq "ISSS08") {
                        $turb .= $mydata{$_}{'wl'}[$sc].",";
                        $turb_qf .= $mydata{$_}{'wl_qf'}[$sc].",";
                    }
                    $psal .= $mydata{$_}{'s'}[$sc].",";
                    $psal_qf .= $mydata{$_}{'s_qf'}[$sc].",";
                    $match = 1;
                    last;
                }
            }
            unless ($match) {
                $temp .= "$misvalout,";
                $temp_qf .= "$misvalout,";
                if ($filetype eq "ISSS08") {
                    $turb .= "$misvalout,";
                    $turb_qf .= "$misvalout,";
                }
                $psal .= "$misvalout,";
                $psal_qf .= "$misvalout,";
            }
        }
    }
    undef $pres;
    $pres = join ",",sort({$a <=> $b} @mypres);
    $stid = "\"";
    $stid .= join "\",\"",@mystations;
    $stid .= "\"";

    # Clean up records
    $timeunix =~ s/,$//;
    $stid =~ s/,$//;
    if ($filetype eq "ISSS08") {
        $z =~ s/,$//;
    }
    $pres =~ s/,$//;
    $lat =~ s/,$//;
    $lon =~ s/,$//;
    $temp =~ s/,$//;
    $temp_qf =~ s/,$//;
    if ($filetype eq "ISSS08") {
        $turb =~ s/,$//;
        $turb_qf =~ s/,$//;
    }
    $psal =~ s/,$//;
    $psal_qf =~ s/,$//;

    # Dump to file
    s/\+time/$timeunix/ for (@cdlout);
    s/\+stid/$stid/ for (@cdlout);
    s/\+lat/$lat/ for (@cdlout);
    s/\+lon/$lon/ for (@cdlout);
    if ($filetype eq "ISSS08") {
        s/\+bdepth/$z/ for (@cdlout);
    }
    s/\+pres/$pres/ for (@cdlout);
    s/\+temp_qf/$temp_qf/ for (@cdlout);
    s/\+temp/$temp/ for (@cdlout);
    if ($filetype eq "ISSS08") {
        s/\+turb_qf/$turb_qf/ for (@cdlout);
        s/\+turb/$turb/ for (@cdlout);
    }
    s/\+psal_qf/$psal_qf/ for (@cdlout);
    s/\+psal/$psal/ for (@cdlout);

    return(@cdlout);
}

##sub transpose {
##  map {
##    my $j = $_;
##    [ map $_[$_][$j], 0..$#_ ]
##  } 0..$#{$_[0]};
##}

sub sort_matrix($$) {
    my $ref_matrix = $_[0];
    my @indexMatrix = @{$_[1]};

    my @indexes = map {$_->[0]} @indexMatrix;
    my @operators = map {$_->[1] ? ' cmp ' : ' <=> '} @indexMatrix;
    my @directions = map {$_->[2]} @indexMatrix;

    my $body_code = '';
    my @body_array;
    for (my $i = 0; $i <= $#indexes; $i++) {
        if ($directions[$i]) {
            push(@body_array, "(\$a->[$i]" . $operators[$i]  . "\$b->[$i])");
        } else {
            push(@body_array, "(\$b->[$i]" . $operators[$i]  . "\$a->[$i])");
        };
    };
    $body_code = join( ' or ', @body_array);

    my $array_code = '(map { [' . join(q(, ), map {"\$_->[$_]"} @indexes) . ', $_]} @$ref_matrix)';

    my $code = "map {\$_->[-1]} (sort { $body_code} $array_code)";
    my @result = eval $code;
    return [@result];
};

